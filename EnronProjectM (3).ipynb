{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Identify fraud from Enron Email\n",
    "\n",
    "### Enron became a symbol for fraud \n",
    "# The spectacular collapse of a giant american company in electric field was not only an end to the company\n",
    "# but brought also a massive change for the american and global economy. \n",
    "# In 2001 Enron announced results for 3rd quarter and at the same time to a big surprise of shareholders a banckruptacy.\n",
    "# In this project I'd like to focus on the most influencial workers of Enron which are obviously involved in the fraud.\n",
    "# The most famous is CEO Jeffrey Keith \"Jeff\" Skilling and a chairman  Kenneth Lay of Enron \n",
    "# during most of the time when the crime occured.\n",
    "# We will see their salaries, bonuses and stocks which are quite interesting.\n",
    "# \n",
    "\n",
    "# Going through given dataset with e-mails within Enron co-workers we will discover a POI - Person of Interest,\n",
    "# basically a person suspected to participate in the fraud.\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Firstly, let's load the necessary data and packages. \n",
    "# I am going to create a dataframe in pandas and then with the use of numpy arrays and matplotlib visualize it.\n",
    "# To further analysis in classyfing will need Sklearn, GaussianNB,... i co jeszcze?\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "import random\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "import pandas as pd\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "### Let's load my dictionary providede by Udacity\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the type of my dataset, as we see it's a dictionary\n",
    "type(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# By converting the dictionary to a dataframe with pandas it will be easier and faster to work with it:\n",
    "enron_dataf = pd.DataFrame.from_records(list(data_dict.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mark.metts@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94299</td>\n",
       "      <td>29</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1740</td>\n",
       "      <td>False</td>\n",
       "      <td>585062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365788</td>\n",
       "      <td>702</td>\n",
       "      <td>807</td>\n",
       "      <td>1061827</td>\n",
       "      <td>585062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>1200000</td>\n",
       "      <td>1295738</td>\n",
       "      <td>-1386055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6680544</td>\n",
       "      <td>11200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1586055</td>\n",
       "      <td>2660303</td>\n",
       "      <td>False</td>\n",
       "      <td>3942714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5634343</td>\n",
       "      <td>10623258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <td>350000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-400729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>steven.elliott@enron.com</td>\n",
       "      <td>4890344</td>\n",
       "      <td>78552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12961</td>\n",
       "      <td>False</td>\n",
       "      <td>1788391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211725</td>\n",
       "      <td>6678735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bill.cordes@enron.com</td>\n",
       "      <td>651850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>386335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1038185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <td>1500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3117011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kevin.hannon@enron.com</td>\n",
       "      <td>5538001</td>\n",
       "      <td>34039</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>1617011</td>\n",
       "      <td>11350</td>\n",
       "      <td>True</td>\n",
       "      <td>853064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>243293</td>\n",
       "      <td>1035</td>\n",
       "      <td>1045</td>\n",
       "      <td>288682</td>\n",
       "      <td>6391065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    bonus deferral_payments deferred_income director_fees  \\\n",
       "METTS MARK         600000               NaN             NaN           NaN   \n",
       "BAXTER JOHN C     1200000           1295738        -1386055           NaN   \n",
       "ELLIOTT STEVEN     350000               NaN         -400729           NaN   \n",
       "CORDES WILLIAM R      NaN               NaN             NaN           NaN   \n",
       "HANNON KEVIN P    1500000               NaN        -3117011           NaN   \n",
       "\n",
       "                             email_address exercised_stock_options expenses  \\\n",
       "METTS MARK            mark.metts@enron.com                     NaN    94299   \n",
       "BAXTER JOHN C                          NaN                 6680544    11200   \n",
       "ELLIOTT STEVEN    steven.elliott@enron.com                 4890344    78552   \n",
       "CORDES WILLIAM R     bill.cordes@enron.com                  651850      NaN   \n",
       "HANNON KEVIN P      kevin.hannon@enron.com                 5538001    34039   \n",
       "\n",
       "                 from_messages from_poi_to_this_person  \\\n",
       "METTS MARK                  29                      38   \n",
       "BAXTER JOHN C              NaN                     NaN   \n",
       "ELLIOTT STEVEN             NaN                     NaN   \n",
       "CORDES WILLIAM R            12                      10   \n",
       "HANNON KEVIN P              32                      32   \n",
       "\n",
       "                 from_this_person_to_poi        ...         \\\n",
       "METTS MARK                             1        ...          \n",
       "BAXTER JOHN C                        NaN        ...          \n",
       "ELLIOTT STEVEN                       NaN        ...          \n",
       "CORDES WILLIAM R                       0        ...          \n",
       "HANNON KEVIN P                        21        ...          \n",
       "\n",
       "                 long_term_incentive    other    poi  restricted_stock  \\\n",
       "METTS MARK                       NaN     1740  False            585062   \n",
       "BAXTER JOHN C                1586055  2660303  False           3942714   \n",
       "ELLIOTT STEVEN                   NaN    12961  False           1788391   \n",
       "CORDES WILLIAM R                 NaN      NaN  False            386335   \n",
       "HANNON KEVIN P               1617011    11350   True            853064   \n",
       "\n",
       "                 restricted_stock_deferred  salary shared_receipt_with_poi  \\\n",
       "METTS MARK                             NaN  365788                     702   \n",
       "BAXTER JOHN C                          NaN  267102                     NaN   \n",
       "ELLIOTT STEVEN                         NaN  170941                     NaN   \n",
       "CORDES WILLIAM R                       NaN     NaN                      58   \n",
       "HANNON KEVIN P                         NaN  243293                    1035   \n",
       "\n",
       "                 to_messages total_payments total_stock_value  \n",
       "METTS MARK               807        1061827            585062  \n",
       "BAXTER JOHN C            NaN        5634343          10623258  \n",
       "ELLIOTT STEVEN           NaN         211725           6678735  \n",
       "CORDES WILLIAM R         764            NaN           1038185  \n",
       "HANNON KEVIN P          1045         288682           6391065  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previosly the index were numbers, but it's easier to set them as names of employees series:\n",
    "employees = pd.Series(list(data_dict.keys()))\n",
    "enron_dataf.set_index(employees, inplace=True)\n",
    "enron_dataf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94299.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>False</td>\n",
       "      <td>585062.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365788.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>1061827.0</td>\n",
       "      <td>585062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1586055.0</td>\n",
       "      <td>2660303.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>267102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>10623258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <td>350000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-400729.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4890344.0</td>\n",
       "      <td>78552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12961.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1788391.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170941.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211725.0</td>\n",
       "      <td>6678735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>651850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>386335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1038185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <td>1500000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3117011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5538001.0</td>\n",
       "      <td>34039.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1617011.0</td>\n",
       "      <td>11350.0</td>\n",
       "      <td>True</td>\n",
       "      <td>853064.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243293.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>288682.0</td>\n",
       "      <td>6391065.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      bonus  deferral_payments  deferred_income  \\\n",
       "METTS MARK         600000.0                0.0              0.0   \n",
       "BAXTER JOHN C     1200000.0          1295738.0       -1386055.0   \n",
       "ELLIOTT STEVEN     350000.0                0.0        -400729.0   \n",
       "CORDES WILLIAM R        0.0                0.0              0.0   \n",
       "HANNON KEVIN P    1500000.0                0.0       -3117011.0   \n",
       "\n",
       "                  director_fees  email_address  exercised_stock_options  \\\n",
       "METTS MARK                  0.0            0.0                      0.0   \n",
       "BAXTER JOHN C               0.0            0.0                6680544.0   \n",
       "ELLIOTT STEVEN              0.0            0.0                4890344.0   \n",
       "CORDES WILLIAM R            0.0            0.0                 651850.0   \n",
       "HANNON KEVIN P              0.0            0.0                5538001.0   \n",
       "\n",
       "                  expenses  from_messages  from_poi_to_this_person  \\\n",
       "METTS MARK         94299.0           29.0                     38.0   \n",
       "BAXTER JOHN C      11200.0            0.0                      0.0   \n",
       "ELLIOTT STEVEN     78552.0            0.0                      0.0   \n",
       "CORDES WILLIAM R       0.0           12.0                     10.0   \n",
       "HANNON KEVIN P     34039.0           32.0                     32.0   \n",
       "\n",
       "                  from_this_person_to_poi        ...          \\\n",
       "METTS MARK                            1.0        ...           \n",
       "BAXTER JOHN C                         0.0        ...           \n",
       "ELLIOTT STEVEN                        0.0        ...           \n",
       "CORDES WILLIAM R                      0.0        ...           \n",
       "HANNON KEVIN P                       21.0        ...           \n",
       "\n",
       "                  long_term_incentive      other    poi  restricted_stock  \\\n",
       "METTS MARK                        0.0     1740.0  False          585062.0   \n",
       "BAXTER JOHN C               1586055.0  2660303.0  False         3942714.0   \n",
       "ELLIOTT STEVEN                    0.0    12961.0  False         1788391.0   \n",
       "CORDES WILLIAM R                  0.0        0.0  False          386335.0   \n",
       "HANNON KEVIN P              1617011.0    11350.0   True          853064.0   \n",
       "\n",
       "                  restricted_stock_deferred    salary  \\\n",
       "METTS MARK                              0.0  365788.0   \n",
       "BAXTER JOHN C                           0.0  267102.0   \n",
       "ELLIOTT STEVEN                          0.0  170941.0   \n",
       "CORDES WILLIAM R                        0.0       0.0   \n",
       "HANNON KEVIN P                          0.0  243293.0   \n",
       "\n",
       "                  shared_receipt_with_poi  to_messages  total_payments  \\\n",
       "METTS MARK                          702.0        807.0       1061827.0   \n",
       "BAXTER JOHN C                         0.0          0.0       5634343.0   \n",
       "ELLIOTT STEVEN                        0.0          0.0        211725.0   \n",
       "CORDES WILLIAM R                     58.0        764.0             0.0   \n",
       "HANNON KEVIN P                     1035.0       1045.0        288682.0   \n",
       "\n",
       "                  total_stock_value  \n",
       "METTS MARK                 585062.0  \n",
       "BAXTER JOHN C            10623258.0  \n",
       "ELLIOTT STEVEN            6678735.0  \n",
       "CORDES WILLIAM R          1038185.0  \n",
       "HANNON KEVIN P            6391065.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to tez zmien to co on napisal\n",
    "# Coerce numeric values into floats or ints; also change NaN to zero:\n",
    "enron_dataf = enron_dataf.apply(lambda x : pd.to_numeric(x, errors = 'coerce')).copy().fillna(0)\n",
    "enron_dataf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94299.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>False</td>\n",
       "      <td>585062.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365788.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>1061827.0</td>\n",
       "      <td>585062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1586055.0</td>\n",
       "      <td>2660303.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>267102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>10623258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <td>350000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-400729.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4890344.0</td>\n",
       "      <td>78552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12961.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1788391.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170941.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211725.0</td>\n",
       "      <td>6678735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>651850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>386335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1038185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <td>1500000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3117011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5538001.0</td>\n",
       "      <td>34039.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1617011.0</td>\n",
       "      <td>11350.0</td>\n",
       "      <td>True</td>\n",
       "      <td>853064.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243293.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>288682.0</td>\n",
       "      <td>6391065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MORDAUNT KRISTINA M</th>\n",
       "      <td>325000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35018.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>False</td>\n",
       "      <td>208510.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>267093.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>628522.0</td>\n",
       "      <td>208510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEYER ROCKFORD G</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1848227.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>493489.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>462384.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>1848227.0</td>\n",
       "      <td>955873.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCMAHON JEFFREY</th>\n",
       "      <td>2600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1104054.0</td>\n",
       "      <td>137108.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>694862.0</td>\n",
       "      <td>297353.0</td>\n",
       "      <td>False</td>\n",
       "      <td>558801.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370448.0</td>\n",
       "      <td>2228.0</td>\n",
       "      <td>2355.0</td>\n",
       "      <td>4099771.0</td>\n",
       "      <td>1662855.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HORTON STANLEY C</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3131860.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5210569.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2046079.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>2350.0</td>\n",
       "      <td>3131860.0</td>\n",
       "      <td>7256648.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIPER GREGORY F</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>1130036.0</td>\n",
       "      <td>-33333.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>880290.0</td>\n",
       "      <td>43057.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>778.0</td>\n",
       "      <td>False</td>\n",
       "      <td>409554.0</td>\n",
       "      <td>-409554.0</td>\n",
       "      <td>197091.0</td>\n",
       "      <td>742.0</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>1737629.0</td>\n",
       "      <td>880290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUMPHREY GENE E</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2964506.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2282768.0</td>\n",
       "      <td>4994.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130724.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3100224.0</td>\n",
       "      <td>2282768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMANOFF ADAM S</th>\n",
       "      <td>788750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53122.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288589.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1130461.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACHMAN JEREMY M</th>\n",
       "      <td>850000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>765313.0</td>\n",
       "      <td>84208.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>831809.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>False</td>\n",
       "      <td>189041.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248546.0</td>\n",
       "      <td>2326.0</td>\n",
       "      <td>2475.0</td>\n",
       "      <td>2014835.0</td>\n",
       "      <td>954354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUNDE MARTIN</th>\n",
       "      <td>700000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>476451.0</td>\n",
       "      <td>111122.0</td>\n",
       "      <td>False</td>\n",
       "      <td>698920.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>257486.0</td>\n",
       "      <td>2565.0</td>\n",
       "      <td>2647.0</td>\n",
       "      <td>1545059.0</td>\n",
       "      <td>698920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GIBBS DANA R</th>\n",
       "      <td>0.0</td>\n",
       "      <td>504610.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2218275.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461912.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>966522.0</td>\n",
       "      <td>2218275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOWRY CHARLES P</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>153686.0</td>\n",
       "      <td>-153686.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLWELL WESLEY</th>\n",
       "      <td>1200000.0</td>\n",
       "      <td>27610.0</td>\n",
       "      <td>-144062.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16514.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101740.0</td>\n",
       "      <td>True</td>\n",
       "      <td>698242.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288542.0</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>1758.0</td>\n",
       "      <td>1490344.0</td>\n",
       "      <td>698242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MULLER MARK S</th>\n",
       "      <td>1100000.0</td>\n",
       "      <td>842924.0</td>\n",
       "      <td>-719000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1056320.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1725545.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>False</td>\n",
       "      <td>360528.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>251654.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>3202070.0</td>\n",
       "      <td>1416848.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JACKSON CHARLENE R</th>\n",
       "      <td>250000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185063.0</td>\n",
       "      <td>10181.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2435.0</td>\n",
       "      <td>False</td>\n",
       "      <td>540672.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288558.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>551174.0</td>\n",
       "      <td>725735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WESTFAHL RICHARD K</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51870.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256191.0</td>\n",
       "      <td>401130.0</td>\n",
       "      <td>False</td>\n",
       "      <td>384930.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63744.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>762135.0</td>\n",
       "      <td>384930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALTERS GARETH W</th>\n",
       "      <td>0.0</td>\n",
       "      <td>53625.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1030329.0</td>\n",
       "      <td>33785.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87410.0</td>\n",
       "      <td>1030329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALLS JR ROBERT H</th>\n",
       "      <td>850000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4346544.0</td>\n",
       "      <td>50936.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540751.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1552453.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>357091.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>1798780.0</td>\n",
       "      <td>5898997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KITCHEN LOUISE</th>\n",
       "      <td>3100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81042.0</td>\n",
       "      <td>5774.0</td>\n",
       "      <td>1728.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93925.0</td>\n",
       "      <td>False</td>\n",
       "      <td>466101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271442.0</td>\n",
       "      <td>3669.0</td>\n",
       "      <td>8305.0</td>\n",
       "      <td>3471141.0</td>\n",
       "      <td>547143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAN RONNIE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-98784.0</td>\n",
       "      <td>98784.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>32460.0</td>\n",
       "      <td>-32460.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BELFER ROBERT</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-102500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44093.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102500.0</td>\n",
       "      <td>-44093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHANKMAN JEFFREY A</th>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1441898.0</td>\n",
       "      <td>178979.0</td>\n",
       "      <td>2681.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>554422.0</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>False</td>\n",
       "      <td>630137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304110.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>3221.0</td>\n",
       "      <td>3038702.0</td>\n",
       "      <td>2072035.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WODRASKA JOHN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189583.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189583.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERGSIEKER RICHARD P</th>\n",
       "      <td>250000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-485813.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59175.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180250.0</td>\n",
       "      <td>427316.0</td>\n",
       "      <td>False</td>\n",
       "      <td>659249.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187922.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>618850.0</td>\n",
       "      <td>659249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URQUHART JOHN A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-36666.0</td>\n",
       "      <td>36666.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228656.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228656.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIBI PHILIPPE A</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1465734.0</td>\n",
       "      <td>38559.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>369721.0</td>\n",
       "      <td>425688.0</td>\n",
       "      <td>False</td>\n",
       "      <td>378082.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213625.0</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>2047593.0</td>\n",
       "      <td>1843816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REYNOLDS LAWRENCE</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>51365.0</td>\n",
       "      <td>-200000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4160672.0</td>\n",
       "      <td>8409.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156250.0</td>\n",
       "      <td>202052.0</td>\n",
       "      <td>False</td>\n",
       "      <td>201483.0</td>\n",
       "      <td>-140264.0</td>\n",
       "      <td>76399.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>394475.0</td>\n",
       "      <td>4221891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIMICHELE RICHARD G</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8191755.0</td>\n",
       "      <td>35812.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>694862.0</td>\n",
       "      <td>374689.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126027.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>262788.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2368151.0</td>\n",
       "      <td>8317782.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>2604490.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-2604490.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARTER REBECCA C</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-159792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>False</td>\n",
       "      <td>307301.0</td>\n",
       "      <td>-307301.0</td>\n",
       "      <td>261809.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>477557.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUCHANAN HAROLD G</th>\n",
       "      <td>500000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>825464.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304805.0</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>False</td>\n",
       "      <td>189041.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248017.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>1054637.0</td>\n",
       "      <td>1014505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAP SOON</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192758.0</td>\n",
       "      <td>55097.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55097.0</td>\n",
       "      <td>192758.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MURRAY JULIA H</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400478.0</td>\n",
       "      <td>57580.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>False</td>\n",
       "      <td>196983.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229284.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>2192.0</td>\n",
       "      <td>812194.0</td>\n",
       "      <td>597461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GARLAND C KEVIN</th>\n",
       "      <td>850000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>636246.0</td>\n",
       "      <td>48405.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>375304.0</td>\n",
       "      <td>60814.0</td>\n",
       "      <td>False</td>\n",
       "      <td>259907.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231946.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>1566469.0</td>\n",
       "      <td>896153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DODSON KEITH</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28164.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>774.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221003.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>319941.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAGER F SCOTT</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8308552.0</td>\n",
       "      <td>53947.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147950.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3576206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158403.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360300.0</td>\n",
       "      <td>11884758.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HIRKO JOSEPH</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10259.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30766064.0</td>\n",
       "      <td>77978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2856.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91093.0</td>\n",
       "      <td>30766064.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIETRICH JANET R</th>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1550019.0</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>556416.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>False</td>\n",
       "      <td>315068.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250100.0</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>2572.0</td>\n",
       "      <td>1410464.0</td>\n",
       "      <td>1865087.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DERRICK JR. JAMES V</th>\n",
       "      <td>800000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1284000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8831913.0</td>\n",
       "      <td>51124.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>484000.0</td>\n",
       "      <td>7482.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1787380.0</td>\n",
       "      <td>-1787380.0</td>\n",
       "      <td>492375.0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>2181.0</td>\n",
       "      <td>550981.0</td>\n",
       "      <td>8831913.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FREVERT MARK A</th>\n",
       "      <td>2000000.0</td>\n",
       "      <td>6426990.0</td>\n",
       "      <td>-3367011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10433518.0</td>\n",
       "      <td>86987.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>1617011.0</td>\n",
       "      <td>7427621.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4188667.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1060932.0</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>3275.0</td>\n",
       "      <td>17252530.0</td>\n",
       "      <td>14622185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAI LOU L</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15364167.0</td>\n",
       "      <td>32047.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1829457.0</td>\n",
       "      <td>False</td>\n",
       "      <td>8453763.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261879.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3123383.0</td>\n",
       "      <td>23817930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAY FRANKLIN R</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>260455.0</td>\n",
       "      <td>-201641.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129142.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>False</td>\n",
       "      <td>145796.0</td>\n",
       "      <td>-82782.0</td>\n",
       "      <td>239671.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>827696.0</td>\n",
       "      <td>63014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAYSLETT RODERICK J</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>346663.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>2649.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>346663.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FUGH JOHN L</th>\n",
       "      <td>0.0</td>\n",
       "      <td>50591.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176378.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50591.0</td>\n",
       "      <td>176378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FALLON JAMES B</th>\n",
       "      <td>2500000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>940257.0</td>\n",
       "      <td>95924.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>374347.0</td>\n",
       "      <td>401481.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1392142.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304588.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>3676340.0</td>\n",
       "      <td>2332399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KOENIG MARK E</th>\n",
       "      <td>700000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>671737.0</td>\n",
       "      <td>127017.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>150458.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1248318.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>309946.0</td>\n",
       "      <td>2271.0</td>\n",
       "      <td>2374.0</td>\n",
       "      <td>1587421.0</td>\n",
       "      <td>1920055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAVAGE FRANK</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-121284.0</td>\n",
       "      <td>125034.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IZZO LAWRENCE L</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2165172.0</td>\n",
       "      <td>28093.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>312500.0</td>\n",
       "      <td>1553729.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3654808.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85274.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>1979596.0</td>\n",
       "      <td>5819980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TILNEY ELIZABETH A</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-575000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>591250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>152055.0</td>\n",
       "      <td>False</td>\n",
       "      <td>576792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>247338.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>399393.0</td>\n",
       "      <td>1168042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARTIN AMANDA K</th>\n",
       "      <td>0.0</td>\n",
       "      <td>85430.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2070306.0</td>\n",
       "      <td>8211.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5145434.0</td>\n",
       "      <td>2818454.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349487.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>8407016.0</td>\n",
       "      <td>2070306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY RICHARD B</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>649584.0</td>\n",
       "      <td>-694862.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2542813.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>769862.0</td>\n",
       "      <td>400572.0</td>\n",
       "      <td>False</td>\n",
       "      <td>901657.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330546.0</td>\n",
       "      <td>2333.0</td>\n",
       "      <td>3523.0</td>\n",
       "      <td>2355702.0</td>\n",
       "      <td>3444470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRAMM WENDY L</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119292.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119292.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAUSEY RICHARD A</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-235000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30674.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>307895.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2502063.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>415189.0</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1868758.0</td>\n",
       "      <td>2502063.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAYLOR MITCHELL S</th>\n",
       "      <td>600000.0</td>\n",
       "      <td>227449.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3181250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>563798.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>265214.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>1092663.0</td>\n",
       "      <td>3745048.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DONAHUE JR JEFFREY M</th>\n",
       "      <td>800000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-300000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>765920.0</td>\n",
       "      <td>96268.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>False</td>\n",
       "      <td>315068.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278601.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>875760.0</td>\n",
       "      <td>1080988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLISAN JR BEN F</th>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>384728.0</td>\n",
       "      <td>125978.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71023.0</td>\n",
       "      <td>200308.0</td>\n",
       "      <td>True</td>\n",
       "      <td>393818.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274975.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>1272284.0</td>\n",
       "      <td>778546.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          bonus  deferral_payments  deferred_income  \\\n",
       "METTS MARK             600000.0                0.0              0.0   \n",
       "BAXTER JOHN C         1200000.0          1295738.0       -1386055.0   \n",
       "ELLIOTT STEVEN         350000.0                0.0        -400729.0   \n",
       "CORDES WILLIAM R            0.0                0.0              0.0   \n",
       "HANNON KEVIN P        1500000.0                0.0       -3117011.0   \n",
       "MORDAUNT KRISTINA M    325000.0                0.0              0.0   \n",
       "MEYER ROCKFORD G            0.0          1848227.0              0.0   \n",
       "MCMAHON JEFFREY       2600000.0                0.0              0.0   \n",
       "HORTON STANLEY C            0.0          3131860.0              0.0   \n",
       "PIPER GREGORY F        400000.0          1130036.0         -33333.0   \n",
       "HUMPHREY GENE E             0.0          2964506.0              0.0   \n",
       "UMANOFF ADAM S         788750.0                0.0              0.0   \n",
       "BLACHMAN JEREMY M      850000.0                0.0              0.0   \n",
       "SUNDE MARTIN           700000.0                0.0              0.0   \n",
       "GIBBS DANA R                0.0           504610.0              0.0   \n",
       "LOWRY CHARLES P             0.0                0.0              0.0   \n",
       "COLWELL WESLEY        1200000.0            27610.0        -144062.0   \n",
       "MULLER MARK S         1100000.0           842924.0        -719000.0   \n",
       "JACKSON CHARLENE R     250000.0                0.0              0.0   \n",
       "WESTFAHL RICHARD K          0.0                0.0         -10800.0   \n",
       "WALTERS GARETH W            0.0            53625.0              0.0   \n",
       "WALLS JR ROBERT H      850000.0                0.0              0.0   \n",
       "KITCHEN LOUISE        3100000.0                0.0              0.0   \n",
       "CHAN RONNIE                 0.0                0.0         -98784.0   \n",
       "BELFER ROBERT               0.0          -102500.0              0.0   \n",
       "SHANKMAN JEFFREY A    2000000.0                0.0              0.0   \n",
       "WODRASKA JOHN               0.0                0.0              0.0   \n",
       "BERGSIEKER RICHARD P   250000.0                0.0        -485813.0   \n",
       "URQUHART JOHN A             0.0                0.0         -36666.0   \n",
       "BIBI PHILIPPE A       1000000.0                0.0              0.0   \n",
       "...                         ...                ...              ...   \n",
       "REYNOLDS LAWRENCE      100000.0            51365.0        -200000.0   \n",
       "DIMICHELE RICHARD G   1000000.0                0.0              0.0   \n",
       "BHATNAGAR SANJAY            0.0                0.0              0.0   \n",
       "CARTER REBECCA C       300000.0                0.0        -159792.0   \n",
       "BUCHANAN HAROLD G      500000.0                0.0              0.0   \n",
       "YEAP SOON                   0.0                0.0              0.0   \n",
       "MURRAY JULIA H         400000.0                0.0              0.0   \n",
       "GARLAND C KEVIN        850000.0                0.0              0.0   \n",
       "DODSON KEITH            70000.0                0.0              0.0   \n",
       "YEAGER F SCOTT              0.0                0.0              0.0   \n",
       "HIRKO JOSEPH                0.0            10259.0              0.0   \n",
       "DIETRICH JANET R       600000.0                0.0              0.0   \n",
       "DERRICK JR. JAMES V    800000.0                0.0       -1284000.0   \n",
       "FREVERT MARK A        2000000.0          6426990.0       -3367011.0   \n",
       "PAI LOU L             1000000.0                0.0              0.0   \n",
       "BAY FRANKLIN R         400000.0           260455.0        -201641.0   \n",
       "HAYSLETT RODERICK J         0.0                0.0              0.0   \n",
       "FUGH JOHN L                 0.0            50591.0              0.0   \n",
       "FALLON JAMES B        2500000.0                0.0              0.0   \n",
       "KOENIG MARK E          700000.0                0.0              0.0   \n",
       "SAVAGE FRANK                0.0                0.0        -121284.0   \n",
       "IZZO LAWRENCE L             0.0                0.0              0.0   \n",
       "TILNEY ELIZABETH A     300000.0                0.0        -575000.0   \n",
       "MARTIN AMANDA K             0.0            85430.0              0.0   \n",
       "BUY RICHARD B          900000.0           649584.0        -694862.0   \n",
       "GRAMM WENDY L               0.0                0.0              0.0   \n",
       "CAUSEY RICHARD A      1000000.0                0.0        -235000.0   \n",
       "TAYLOR MITCHELL S      600000.0           227449.0              0.0   \n",
       "DONAHUE JR JEFFREY M   800000.0                0.0        -300000.0   \n",
       "GLISAN JR BEN F        600000.0                0.0              0.0   \n",
       "\n",
       "                      director_fees  exercised_stock_options  expenses  \\\n",
       "METTS MARK                      0.0                      0.0   94299.0   \n",
       "BAXTER JOHN C                   0.0                6680544.0   11200.0   \n",
       "ELLIOTT STEVEN                  0.0                4890344.0   78552.0   \n",
       "CORDES WILLIAM R                0.0                 651850.0       0.0   \n",
       "HANNON KEVIN P                  0.0                5538001.0   34039.0   \n",
       "MORDAUNT KRISTINA M             0.0                      0.0   35018.0   \n",
       "MEYER ROCKFORD G                0.0                 493489.0       0.0   \n",
       "MCMAHON JEFFREY                 0.0                1104054.0  137108.0   \n",
       "HORTON STANLEY C                0.0                5210569.0       0.0   \n",
       "PIPER GREGORY F                 0.0                 880290.0   43057.0   \n",
       "HUMPHREY GENE E                 0.0                2282768.0    4994.0   \n",
       "UMANOFF ADAM S                  0.0                      0.0   53122.0   \n",
       "BLACHMAN JEREMY M               0.0                 765313.0   84208.0   \n",
       "SUNDE MARTIN                    0.0                      0.0       0.0   \n",
       "GIBBS DANA R                    0.0                2218275.0       0.0   \n",
       "LOWRY CHARLES P                 0.0                 372205.0       0.0   \n",
       "COLWELL WESLEY                  0.0                      0.0   16514.0   \n",
       "MULLER MARK S                   0.0                1056320.0       0.0   \n",
       "JACKSON CHARLENE R              0.0                 185063.0   10181.0   \n",
       "WESTFAHL RICHARD K              0.0                      0.0   51870.0   \n",
       "WALTERS GARETH W                0.0                1030329.0   33785.0   \n",
       "WALLS JR ROBERT H               0.0                4346544.0   50936.0   \n",
       "KITCHEN LOUISE                  0.0                  81042.0    5774.0   \n",
       "CHAN RONNIE                 98784.0                      0.0       0.0   \n",
       "BELFER ROBERT                3285.0                   3285.0       0.0   \n",
       "SHANKMAN JEFFREY A              0.0                1441898.0  178979.0   \n",
       "WODRASKA JOHN                   0.0                      0.0       0.0   \n",
       "BERGSIEKER RICHARD P            0.0                      0.0   59175.0   \n",
       "URQUHART JOHN A             36666.0                      0.0  228656.0   \n",
       "BIBI PHILIPPE A                 0.0                1465734.0   38559.0   \n",
       "...                             ...                      ...       ...   \n",
       "REYNOLDS LAWRENCE               0.0                4160672.0    8409.0   \n",
       "DIMICHELE RICHARD G             0.0                8191755.0   35812.0   \n",
       "BHATNAGAR SANJAY           137864.0                2604490.0       0.0   \n",
       "CARTER REBECCA C                0.0                      0.0       0.0   \n",
       "BUCHANAN HAROLD G               0.0                 825464.0     600.0   \n",
       "YEAP SOON                       0.0                 192758.0   55097.0   \n",
       "MURRAY JULIA H                  0.0                 400478.0   57580.0   \n",
       "GARLAND C KEVIN                 0.0                 636246.0   48405.0   \n",
       "DODSON KEITH                    0.0                      0.0   28164.0   \n",
       "YEAGER F SCOTT                  0.0                8308552.0   53947.0   \n",
       "HIRKO JOSEPH                    0.0               30766064.0   77978.0   \n",
       "DIETRICH JANET R                0.0                1550019.0    3475.0   \n",
       "DERRICK JR. JAMES V             0.0                8831913.0   51124.0   \n",
       "FREVERT MARK A                  0.0               10433518.0   86987.0   \n",
       "PAI LOU L                       0.0               15364167.0   32047.0   \n",
       "BAY FRANKLIN R                  0.0                      0.0  129142.0   \n",
       "HAYSLETT RODERICK J             0.0                      0.0       0.0   \n",
       "FUGH JOHN L                     0.0                 176378.0       0.0   \n",
       "FALLON JAMES B                  0.0                 940257.0   95924.0   \n",
       "KOENIG MARK E                   0.0                 671737.0  127017.0   \n",
       "SAVAGE FRANK               125034.0                      0.0       0.0   \n",
       "IZZO LAWRENCE L                 0.0                2165172.0   28093.0   \n",
       "TILNEY ELIZABETH A              0.0                 591250.0       0.0   \n",
       "MARTIN AMANDA K                 0.0                2070306.0    8211.0   \n",
       "BUY RICHARD B                   0.0                2542813.0       0.0   \n",
       "GRAMM WENDY L              119292.0                      0.0       0.0   \n",
       "CAUSEY RICHARD A                0.0                      0.0   30674.0   \n",
       "TAYLOR MITCHELL S               0.0                3181250.0       0.0   \n",
       "DONAHUE JR JEFFREY M            0.0                 765920.0   96268.0   \n",
       "GLISAN JR BEN F                 0.0                 384728.0  125978.0   \n",
       "\n",
       "                      from_messages  from_poi_to_this_person  \\\n",
       "METTS MARK                     29.0                     38.0   \n",
       "BAXTER JOHN C                   0.0                      0.0   \n",
       "ELLIOTT STEVEN                  0.0                      0.0   \n",
       "CORDES WILLIAM R               12.0                     10.0   \n",
       "HANNON KEVIN P                 32.0                     32.0   \n",
       "MORDAUNT KRISTINA M             0.0                      0.0   \n",
       "MEYER ROCKFORD G               28.0                      0.0   \n",
       "MCMAHON JEFFREY                48.0                     58.0   \n",
       "HORTON STANLEY C             1073.0                     44.0   \n",
       "PIPER GREGORY F               222.0                     61.0   \n",
       "HUMPHREY GENE E                17.0                     10.0   \n",
       "UMANOFF ADAM S                 18.0                     12.0   \n",
       "BLACHMAN JEREMY M              14.0                     25.0   \n",
       "SUNDE MARTIN                   38.0                     37.0   \n",
       "GIBBS DANA R                   12.0                      0.0   \n",
       "LOWRY CHARLES P                 0.0                      0.0   \n",
       "COLWELL WESLEY                 40.0                    240.0   \n",
       "MULLER MARK S                  16.0                     12.0   \n",
       "JACKSON CHARLENE R             56.0                     25.0   \n",
       "WESTFAHL RICHARD K              0.0                      0.0   \n",
       "WALTERS GARETH W                0.0                      0.0   \n",
       "WALLS JR ROBERT H             146.0                     17.0   \n",
       "KITCHEN LOUISE               1728.0                    251.0   \n",
       "CHAN RONNIE                     0.0                      0.0   \n",
       "BELFER ROBERT                   0.0                      0.0   \n",
       "SHANKMAN JEFFREY A           2681.0                     94.0   \n",
       "WODRASKA JOHN                   0.0                      0.0   \n",
       "BERGSIEKER RICHARD P           59.0                      4.0   \n",
       "URQUHART JOHN A                 0.0                      0.0   \n",
       "BIBI PHILIPPE A                40.0                     23.0   \n",
       "...                             ...                      ...   \n",
       "REYNOLDS LAWRENCE               0.0                      0.0   \n",
       "DIMICHELE RICHARD G             0.0                      0.0   \n",
       "BHATNAGAR SANJAY               29.0                      0.0   \n",
       "CARTER REBECCA C               15.0                     29.0   \n",
       "BUCHANAN HAROLD G             125.0                      0.0   \n",
       "YEAP SOON                       0.0                      0.0   \n",
       "MURRAY JULIA H                 45.0                     11.0   \n",
       "GARLAND C KEVIN                44.0                     10.0   \n",
       "DODSON KEITH                   14.0                     10.0   \n",
       "YEAGER F SCOTT                  0.0                      0.0   \n",
       "HIRKO JOSEPH                    0.0                      0.0   \n",
       "DIETRICH JANET R               63.0                    305.0   \n",
       "DERRICK JR. JAMES V           909.0                     64.0   \n",
       "FREVERT MARK A                 21.0                    242.0   \n",
       "PAI LOU L                       0.0                      0.0   \n",
       "BAY FRANKLIN R                  0.0                      0.0   \n",
       "HAYSLETT RODERICK J          1061.0                     35.0   \n",
       "FUGH JOHN L                     0.0                      0.0   \n",
       "FALLON JAMES B                 75.0                     42.0   \n",
       "KOENIG MARK E                  61.0                     53.0   \n",
       "SAVAGE FRANK                    0.0                      0.0   \n",
       "IZZO LAWRENCE L                19.0                     28.0   \n",
       "TILNEY ELIZABETH A             19.0                     10.0   \n",
       "MARTIN AMANDA K               230.0                      8.0   \n",
       "BUY RICHARD B                1053.0                    156.0   \n",
       "GRAMM WENDY L                   0.0                      0.0   \n",
       "CAUSEY RICHARD A               49.0                     58.0   \n",
       "TAYLOR MITCHELL S              29.0                      0.0   \n",
       "DONAHUE JR JEFFREY M           22.0                    188.0   \n",
       "GLISAN JR BEN F                16.0                     52.0   \n",
       "\n",
       "                      from_this_person_to_poi  loan_advances  \\\n",
       "METTS MARK                                1.0            0.0   \n",
       "BAXTER JOHN C                             0.0            0.0   \n",
       "ELLIOTT STEVEN                            0.0            0.0   \n",
       "CORDES WILLIAM R                          0.0            0.0   \n",
       "HANNON KEVIN P                           21.0            0.0   \n",
       "MORDAUNT KRISTINA M                       0.0            0.0   \n",
       "MEYER ROCKFORD G                          0.0            0.0   \n",
       "MCMAHON JEFFREY                          26.0            0.0   \n",
       "HORTON STANLEY C                         15.0            0.0   \n",
       "PIPER GREGORY F                          48.0            0.0   \n",
       "HUMPHREY GENE E                          17.0            0.0   \n",
       "UMANOFF ADAM S                            0.0            0.0   \n",
       "BLACHMAN JEREMY M                         2.0            0.0   \n",
       "SUNDE MARTIN                             13.0            0.0   \n",
       "GIBBS DANA R                              0.0            0.0   \n",
       "LOWRY CHARLES P                           0.0            0.0   \n",
       "COLWELL WESLEY                           11.0            0.0   \n",
       "MULLER MARK S                             0.0            0.0   \n",
       "JACKSON CHARLENE R                       19.0            0.0   \n",
       "WESTFAHL RICHARD K                        0.0            0.0   \n",
       "WALTERS GARETH W                          0.0            0.0   \n",
       "WALLS JR ROBERT H                         0.0            0.0   \n",
       "KITCHEN LOUISE                          194.0            0.0   \n",
       "CHAN RONNIE                               0.0            0.0   \n",
       "BELFER ROBERT                             0.0            0.0   \n",
       "SHANKMAN JEFFREY A                       83.0            0.0   \n",
       "WODRASKA JOHN                             0.0            0.0   \n",
       "BERGSIEKER RICHARD P                      0.0            0.0   \n",
       "URQUHART JOHN A                           0.0            0.0   \n",
       "BIBI PHILIPPE A                           8.0            0.0   \n",
       "...                                       ...            ...   \n",
       "REYNOLDS LAWRENCE                         0.0            0.0   \n",
       "DIMICHELE RICHARD G                       0.0            0.0   \n",
       "BHATNAGAR SANJAY                          1.0            0.0   \n",
       "CARTER REBECCA C                          7.0            0.0   \n",
       "BUCHANAN HAROLD G                         0.0            0.0   \n",
       "YEAP SOON                                 0.0            0.0   \n",
       "MURRAY JULIA H                            2.0            0.0   \n",
       "GARLAND C KEVIN                          27.0            0.0   \n",
       "DODSON KEITH                              3.0            0.0   \n",
       "YEAGER F SCOTT                            0.0            0.0   \n",
       "HIRKO JOSEPH                              0.0            0.0   \n",
       "DIETRICH JANET R                         14.0            0.0   \n",
       "DERRICK JR. JAMES V                      20.0            0.0   \n",
       "FREVERT MARK A                            6.0      2000000.0   \n",
       "PAI LOU L                                 0.0            0.0   \n",
       "BAY FRANKLIN R                            0.0            0.0   \n",
       "HAYSLETT RODERICK J                      38.0            0.0   \n",
       "FUGH JOHN L                               0.0            0.0   \n",
       "FALLON JAMES B                           37.0            0.0   \n",
       "KOENIG MARK E                            15.0            0.0   \n",
       "SAVAGE FRANK                              0.0            0.0   \n",
       "IZZO LAWRENCE L                           5.0            0.0   \n",
       "TILNEY ELIZABETH A                       11.0            0.0   \n",
       "MARTIN AMANDA K                           0.0            0.0   \n",
       "BUY RICHARD B                            71.0            0.0   \n",
       "GRAMM WENDY L                             0.0            0.0   \n",
       "CAUSEY RICHARD A                         12.0            0.0   \n",
       "TAYLOR MITCHELL S                         0.0            0.0   \n",
       "DONAHUE JR JEFFREY M                     11.0            0.0   \n",
       "GLISAN JR BEN F                           6.0            0.0   \n",
       "\n",
       "                      long_term_incentive      other    poi  restricted_stock  \\\n",
       "METTS MARK                            0.0     1740.0  False          585062.0   \n",
       "BAXTER JOHN C                   1586055.0  2660303.0  False         3942714.0   \n",
       "ELLIOTT STEVEN                        0.0    12961.0  False         1788391.0   \n",
       "CORDES WILLIAM R                      0.0        0.0  False          386335.0   \n",
       "HANNON KEVIN P                  1617011.0    11350.0   True          853064.0   \n",
       "MORDAUNT KRISTINA M                   0.0     1411.0  False          208510.0   \n",
       "MEYER ROCKFORD G                      0.0        0.0  False          462384.0   \n",
       "MCMAHON JEFFREY                  694862.0   297353.0  False          558801.0   \n",
       "HORTON STANLEY C                      0.0        0.0  False         2046079.0   \n",
       "PIPER GREGORY F                       0.0      778.0  False          409554.0   \n",
       "HUMPHREY GENE E                       0.0        0.0  False               0.0   \n",
       "UMANOFF ADAM S                        0.0        0.0  False               0.0   \n",
       "BLACHMAN JEREMY M                831809.0      272.0  False          189041.0   \n",
       "SUNDE MARTIN                     476451.0   111122.0  False          698920.0   \n",
       "GIBBS DANA R                     461912.0        0.0  False               0.0   \n",
       "LOWRY CHARLES P                       0.0        0.0  False          153686.0   \n",
       "COLWELL WESLEY                        0.0   101740.0   True          698242.0   \n",
       "MULLER MARK S                   1725545.0      947.0  False          360528.0   \n",
       "JACKSON CHARLENE R                    0.0     2435.0  False          540672.0   \n",
       "WESTFAHL RICHARD K               256191.0   401130.0  False          384930.0   \n",
       "WALTERS GARETH W                      0.0        0.0  False               0.0   \n",
       "WALLS JR ROBERT H                540751.0        2.0  False         1552453.0   \n",
       "KITCHEN LOUISE                        0.0    93925.0  False          466101.0   \n",
       "CHAN RONNIE                           0.0        0.0  False           32460.0   \n",
       "BELFER ROBERT                         0.0        0.0  False               0.0   \n",
       "SHANKMAN JEFFREY A               554422.0     1191.0  False          630137.0   \n",
       "WODRASKA JOHN                         0.0   189583.0  False               0.0   \n",
       "BERGSIEKER RICHARD P             180250.0   427316.0  False          659249.0   \n",
       "URQUHART JOHN A                       0.0        0.0  False               0.0   \n",
       "BIBI PHILIPPE A                  369721.0   425688.0  False          378082.0   \n",
       "...                                   ...        ...    ...               ...   \n",
       "REYNOLDS LAWRENCE                156250.0   202052.0  False          201483.0   \n",
       "DIMICHELE RICHARD G              694862.0   374689.0  False          126027.0   \n",
       "BHATNAGAR SANJAY                      0.0   137864.0  False        -2604490.0   \n",
       "CARTER REBECCA C                  75000.0      540.0  False          307301.0   \n",
       "BUCHANAN HAROLD G                304805.0     1215.0  False          189041.0   \n",
       "YEAP SOON                             0.0        0.0  False               0.0   \n",
       "MURRAY JULIA H                   125000.0      330.0  False          196983.0   \n",
       "GARLAND C KEVIN                  375304.0    60814.0  False          259907.0   \n",
       "DODSON KEITH                          0.0      774.0  False               0.0   \n",
       "YEAGER F SCOTT                        0.0   147950.0   True         3576206.0   \n",
       "HIRKO JOSEPH                          0.0     2856.0   True               0.0   \n",
       "DIETRICH JANET R                 556416.0      473.0  False          315068.0   \n",
       "DERRICK JR. JAMES V              484000.0     7482.0  False         1787380.0   \n",
       "FREVERT MARK A                  1617011.0  7427621.0  False         4188667.0   \n",
       "PAI LOU L                             0.0  1829457.0  False         8453763.0   \n",
       "BAY FRANKLIN R                        0.0       69.0  False          145796.0   \n",
       "HAYSLETT RODERICK J                   0.0        0.0  False          346663.0   \n",
       "FUGH JOHN L                           0.0        0.0  False               0.0   \n",
       "FALLON JAMES B                   374347.0   401481.0  False         1392142.0   \n",
       "KOENIG MARK E                    300000.0   150458.0   True         1248318.0   \n",
       "SAVAGE FRANK                          0.0        0.0  False               0.0   \n",
       "IZZO LAWRENCE L                  312500.0  1553729.0  False         3654808.0   \n",
       "TILNEY ELIZABETH A               275000.0   152055.0  False          576792.0   \n",
       "MARTIN AMANDA K                 5145434.0  2818454.0  False               0.0   \n",
       "BUY RICHARD B                    769862.0   400572.0  False          901657.0   \n",
       "GRAMM WENDY L                         0.0        0.0  False               0.0   \n",
       "CAUSEY RICHARD A                 350000.0   307895.0   True         2502063.0   \n",
       "TAYLOR MITCHELL S                     0.0        0.0  False          563798.0   \n",
       "DONAHUE JR JEFFREY M                  0.0      891.0  False          315068.0   \n",
       "GLISAN JR BEN F                   71023.0   200308.0   True          393818.0   \n",
       "\n",
       "                      restricted_stock_deferred     salary  \\\n",
       "METTS MARK                                  0.0   365788.0   \n",
       "BAXTER JOHN C                               0.0   267102.0   \n",
       "ELLIOTT STEVEN                              0.0   170941.0   \n",
       "CORDES WILLIAM R                            0.0        0.0   \n",
       "HANNON KEVIN P                              0.0   243293.0   \n",
       "MORDAUNT KRISTINA M                         0.0   267093.0   \n",
       "MEYER ROCKFORD G                            0.0        0.0   \n",
       "MCMAHON JEFFREY                             0.0   370448.0   \n",
       "HORTON STANLEY C                            0.0        0.0   \n",
       "PIPER GREGORY F                       -409554.0   197091.0   \n",
       "HUMPHREY GENE E                             0.0   130724.0   \n",
       "UMANOFF ADAM S                              0.0   288589.0   \n",
       "BLACHMAN JEREMY M                           0.0   248546.0   \n",
       "SUNDE MARTIN                                0.0   257486.0   \n",
       "GIBBS DANA R                                0.0        0.0   \n",
       "LOWRY CHARLES P                       -153686.0        0.0   \n",
       "COLWELL WESLEY                              0.0   288542.0   \n",
       "MULLER MARK S                               0.0   251654.0   \n",
       "JACKSON CHARLENE R                          0.0   288558.0   \n",
       "WESTFAHL RICHARD K                          0.0    63744.0   \n",
       "WALTERS GARETH W                            0.0        0.0   \n",
       "WALLS JR ROBERT H                           0.0   357091.0   \n",
       "KITCHEN LOUISE                              0.0   271442.0   \n",
       "CHAN RONNIE                            -32460.0        0.0   \n",
       "BELFER ROBERT                           44093.0        0.0   \n",
       "SHANKMAN JEFFREY A                          0.0   304110.0   \n",
       "WODRASKA JOHN                               0.0        0.0   \n",
       "BERGSIEKER RICHARD P                        0.0   187922.0   \n",
       "URQUHART JOHN A                             0.0        0.0   \n",
       "BIBI PHILIPPE A                             0.0   213625.0   \n",
       "...                                         ...        ...   \n",
       "REYNOLDS LAWRENCE                     -140264.0    76399.0   \n",
       "DIMICHELE RICHARD G                         0.0   262788.0   \n",
       "BHATNAGAR SANJAY                     15456290.0        0.0   \n",
       "CARTER REBECCA C                      -307301.0   261809.0   \n",
       "BUCHANAN HAROLD G                           0.0   248017.0   \n",
       "YEAP SOON                                   0.0        0.0   \n",
       "MURRAY JULIA H                              0.0   229284.0   \n",
       "GARLAND C KEVIN                             0.0   231946.0   \n",
       "DODSON KEITH                                0.0   221003.0   \n",
       "YEAGER F SCOTT                              0.0   158403.0   \n",
       "HIRKO JOSEPH                                0.0        0.0   \n",
       "DIETRICH JANET R                            0.0   250100.0   \n",
       "DERRICK JR. JAMES V                  -1787380.0   492375.0   \n",
       "FREVERT MARK A                              0.0  1060932.0   \n",
       "PAI LOU L                                   0.0   261879.0   \n",
       "BAY FRANKLIN R                         -82782.0   239671.0   \n",
       "HAYSLETT RODERICK J                         0.0        0.0   \n",
       "FUGH JOHN L                                 0.0        0.0   \n",
       "FALLON JAMES B                              0.0   304588.0   \n",
       "KOENIG MARK E                               0.0   309946.0   \n",
       "SAVAGE FRANK                                0.0        0.0   \n",
       "IZZO LAWRENCE L                             0.0    85274.0   \n",
       "TILNEY ELIZABETH A                          0.0   247338.0   \n",
       "MARTIN AMANDA K                             0.0   349487.0   \n",
       "BUY RICHARD B                               0.0   330546.0   \n",
       "GRAMM WENDY L                               0.0        0.0   \n",
       "CAUSEY RICHARD A                            0.0   415189.0   \n",
       "TAYLOR MITCHELL S                           0.0   265214.0   \n",
       "DONAHUE JR JEFFREY M                        0.0   278601.0   \n",
       "GLISAN JR BEN F                             0.0   274975.0   \n",
       "\n",
       "                      shared_receipt_with_poi  to_messages  total_payments  \\\n",
       "METTS MARK                              702.0        807.0       1061827.0   \n",
       "BAXTER JOHN C                             0.0          0.0       5634343.0   \n",
       "ELLIOTT STEVEN                            0.0          0.0        211725.0   \n",
       "CORDES WILLIAM R                         58.0        764.0             0.0   \n",
       "HANNON KEVIN P                         1035.0       1045.0        288682.0   \n",
       "MORDAUNT KRISTINA M                       0.0          0.0        628522.0   \n",
       "MEYER ROCKFORD G                         22.0        232.0       1848227.0   \n",
       "MCMAHON JEFFREY                        2228.0       2355.0       4099771.0   \n",
       "HORTON STANLEY C                       1074.0       2350.0       3131860.0   \n",
       "PIPER GREGORY F                         742.0       1238.0       1737629.0   \n",
       "HUMPHREY GENE E                         119.0        128.0       3100224.0   \n",
       "UMANOFF ADAM S                           41.0        111.0       1130461.0   \n",
       "BLACHMAN JEREMY M                      2326.0       2475.0       2014835.0   \n",
       "SUNDE MARTIN                           2565.0       2647.0       1545059.0   \n",
       "GIBBS DANA R                             23.0        169.0        966522.0   \n",
       "LOWRY CHARLES P                           0.0          0.0             0.0   \n",
       "COLWELL WESLEY                         1132.0       1758.0       1490344.0   \n",
       "MULLER MARK S                           114.0        136.0       3202070.0   \n",
       "JACKSON CHARLENE R                      117.0        258.0        551174.0   \n",
       "WESTFAHL RICHARD K                        0.0          0.0        762135.0   \n",
       "WALTERS GARETH W                          0.0          0.0         87410.0   \n",
       "WALLS JR ROBERT H                       215.0        671.0       1798780.0   \n",
       "KITCHEN LOUISE                         3669.0       8305.0       3471141.0   \n",
       "CHAN RONNIE                               0.0          0.0             0.0   \n",
       "BELFER ROBERT                             0.0          0.0        102500.0   \n",
       "SHANKMAN JEFFREY A                     1730.0       3221.0       3038702.0   \n",
       "WODRASKA JOHN                             0.0          0.0        189583.0   \n",
       "BERGSIEKER RICHARD P                    233.0        383.0        618850.0   \n",
       "URQUHART JOHN A                           0.0          0.0        228656.0   \n",
       "BIBI PHILIPPE A                        1336.0       1607.0       2047593.0   \n",
       "...                                       ...          ...             ...   \n",
       "REYNOLDS LAWRENCE                         0.0          0.0        394475.0   \n",
       "DIMICHELE RICHARD G                       0.0          0.0       2368151.0   \n",
       "BHATNAGAR SANJAY                        463.0        523.0      15456290.0   \n",
       "CARTER REBECCA C                        196.0        312.0        477557.0   \n",
       "BUCHANAN HAROLD G                        23.0       1088.0       1054637.0   \n",
       "YEAP SOON                                 0.0          0.0         55097.0   \n",
       "MURRAY JULIA H                          395.0       2192.0        812194.0   \n",
       "GARLAND C KEVIN                         178.0        209.0       1566469.0   \n",
       "DODSON KEITH                            114.0        176.0        319941.0   \n",
       "YEAGER F SCOTT                            0.0          0.0        360300.0   \n",
       "HIRKO JOSEPH                              0.0          0.0         91093.0   \n",
       "DIETRICH JANET R                       1902.0       2572.0       1410464.0   \n",
       "DERRICK JR. JAMES V                    1401.0       2181.0        550981.0   \n",
       "FREVERT MARK A                         2979.0       3275.0      17252530.0   \n",
       "PAI LOU L                                 0.0          0.0       3123383.0   \n",
       "BAY FRANKLIN R                            0.0          0.0        827696.0   \n",
       "HAYSLETT RODERICK J                     571.0       2649.0             0.0   \n",
       "FUGH JOHN L                               0.0          0.0         50591.0   \n",
       "FALLON JAMES B                         1604.0       1755.0       3676340.0   \n",
       "KOENIG MARK E                          2271.0       2374.0       1587421.0   \n",
       "SAVAGE FRANK                              0.0          0.0          3750.0   \n",
       "IZZO LAWRENCE L                         437.0        496.0       1979596.0   \n",
       "TILNEY ELIZABETH A                      379.0        460.0        399393.0   \n",
       "MARTIN AMANDA K                         477.0       1522.0       8407016.0   \n",
       "BUY RICHARD B                          2333.0       3523.0       2355702.0   \n",
       "GRAMM WENDY L                             0.0          0.0        119292.0   \n",
       "CAUSEY RICHARD A                       1585.0       1892.0       1868758.0   \n",
       "TAYLOR MITCHELL S                       300.0        533.0       1092663.0   \n",
       "DONAHUE JR JEFFREY M                    772.0        865.0        875760.0   \n",
       "GLISAN JR BEN F                         874.0        873.0       1272284.0   \n",
       "\n",
       "                      total_stock_value  \n",
       "METTS MARK                     585062.0  \n",
       "BAXTER JOHN C                10623258.0  \n",
       "ELLIOTT STEVEN                6678735.0  \n",
       "CORDES WILLIAM R              1038185.0  \n",
       "HANNON KEVIN P                6391065.0  \n",
       "MORDAUNT KRISTINA M            208510.0  \n",
       "MEYER ROCKFORD G               955873.0  \n",
       "MCMAHON JEFFREY               1662855.0  \n",
       "HORTON STANLEY C              7256648.0  \n",
       "PIPER GREGORY F                880290.0  \n",
       "HUMPHREY GENE E               2282768.0  \n",
       "UMANOFF ADAM S                      0.0  \n",
       "BLACHMAN JEREMY M              954354.0  \n",
       "SUNDE MARTIN                   698920.0  \n",
       "GIBBS DANA R                  2218275.0  \n",
       "LOWRY CHARLES P                372205.0  \n",
       "COLWELL WESLEY                 698242.0  \n",
       "MULLER MARK S                 1416848.0  \n",
       "JACKSON CHARLENE R             725735.0  \n",
       "WESTFAHL RICHARD K             384930.0  \n",
       "WALTERS GARETH W              1030329.0  \n",
       "WALLS JR ROBERT H             5898997.0  \n",
       "KITCHEN LOUISE                 547143.0  \n",
       "CHAN RONNIE                         0.0  \n",
       "BELFER ROBERT                  -44093.0  \n",
       "SHANKMAN JEFFREY A            2072035.0  \n",
       "WODRASKA JOHN                       0.0  \n",
       "BERGSIEKER RICHARD P           659249.0  \n",
       "URQUHART JOHN A                     0.0  \n",
       "BIBI PHILIPPE A               1843816.0  \n",
       "...                                 ...  \n",
       "REYNOLDS LAWRENCE             4221891.0  \n",
       "DIMICHELE RICHARD G           8317782.0  \n",
       "BHATNAGAR SANJAY                    0.0  \n",
       "CARTER REBECCA C                    0.0  \n",
       "BUCHANAN HAROLD G             1014505.0  \n",
       "YEAP SOON                      192758.0  \n",
       "MURRAY JULIA H                 597461.0  \n",
       "GARLAND C KEVIN                896153.0  \n",
       "DODSON KEITH                        0.0  \n",
       "YEAGER F SCOTT               11884758.0  \n",
       "HIRKO JOSEPH                 30766064.0  \n",
       "DIETRICH JANET R              1865087.0  \n",
       "DERRICK JR. JAMES V           8831913.0  \n",
       "FREVERT MARK A               14622185.0  \n",
       "PAI LOU L                    23817930.0  \n",
       "BAY FRANKLIN R                  63014.0  \n",
       "HAYSLETT RODERICK J            346663.0  \n",
       "FUGH JOHN L                    176378.0  \n",
       "FALLON JAMES B                2332399.0  \n",
       "KOENIG MARK E                 1920055.0  \n",
       "SAVAGE FRANK                        0.0  \n",
       "IZZO LAWRENCE L               5819980.0  \n",
       "TILNEY ELIZABETH A            1168042.0  \n",
       "MARTIN AMANDA K               2070306.0  \n",
       "BUY RICHARD B                 3444470.0  \n",
       "GRAMM WENDY L                       0.0  \n",
       "CAUSEY RICHARD A              2502063.0  \n",
       "TAYLOR MITCHELL S             3745048.0  \n",
       "DONAHUE JR JEFFREY M          1080988.0  \n",
       "GLISAN JR BEN F                778546.0  \n",
       "\n",
       "[146 rows x 20 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from above table we can see that some of the data can be interrupting with our analysis\n",
    "# so let's get rid off, for example the e-mail address column \n",
    "\n",
    "enron_dataf.drop('email_address', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's load the data and answer a few simple questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we see the whole data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bonus                            5.6e+06\n",
       "deferral_payments                      0\n",
       "deferred_income                        0\n",
       "director_fees                          0\n",
       "email_address                          0\n",
       "exercised_stock_options        1.925e+07\n",
       "expenses                           29336\n",
       "from_messages                        108\n",
       "from_poi_to_this_person               88\n",
       "from_this_person_to_poi               30\n",
       "loan_advances                          0\n",
       "long_term_incentive             1.92e+06\n",
       "other                              22122\n",
       "poi                                 True\n",
       "restricted_stock             6.84367e+06\n",
       "restricted_stock_deferred              0\n",
       "salary                       1.11126e+06\n",
       "shared_receipt_with_poi             2042\n",
       "to_messages                         3627\n",
       "total_payments               8.68272e+06\n",
       "total_stock_value            2.60937e+07\n",
       "Name: SKILLING JEFFREY K, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what features we have about the Enron's CEO:\n",
    "\n",
    "enron_dataf.loc['SKILLING JEFFREY K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'bonus', u'deferral_payments', u'deferred_income', u'director_fees',\n",
      "       u'email_address', u'exercised_stock_options', u'expenses',\n",
      "       u'from_messages', u'from_poi_to_this_person',\n",
      "       u'from_this_person_to_poi', u'loan_advances', u'long_term_incentive',\n",
      "       u'other', u'poi', u'restricted_stock', u'restricted_stock_deferred',\n",
      "       u'salary', u'shared_receipt_with_poi', u'to_messages',\n",
      "       u'total_payments', u'total_stock_value'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print enron_dataf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    128\n",
       "True      18\n",
       "Name: poi, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we see there are 146 people in our dataset. Only 18 of them are POI  - Persons of Interest\n",
    "enron_dataf['poi'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## OUTLIERS\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to nie działa trzeba cos z tym zrobić"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#chyba dam sobie z tym spokój\n",
    "#enron_dataf.drop['TOTAL', axis = 0, inplace = True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just by reading the file with emails provided by Udacity we see that 'TOTAL' and 'NAN' values bring confusion \n",
    "# to the data. Let's remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## This code below doesn't make sense after removing the dictionary : d_enron_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\") )\n",
    "## What am I supposed to do with this?\n",
    "\n",
    "# As we can see there are some outliers that must be removed for further analysis.\n",
    "# let's get rid off the total, which could cause a chaos. \n",
    "# After that we should remove all NANs and see the 6 top salaries as a list in Enron.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nleQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xce2da20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's visualize the salaries and bonuses of ppl in enrone,that's a good way to find outliers\n",
    "\n",
    "plt.scatter(enron_dataf[\"salary\"][enron_dataf[\"poi\"] == True],enron_dataf[\"bonus\"][enron_dataf[\"poi\"] == True], color = 'r',\n",
    "           label = \"POI\")\n",
    "plt.scatter(enron_dataf[\"salary\"][enron_dataf[\"poi\"] == False],enron_dataf[\"bonus\"][enron_dataf[\"poi\"] == False],color = 'b',\n",
    "           label = \"Not-POI\")\n",
    "    \n",
    "plt.xlabel(\"Salary\")\n",
    "plt.ylabel(\"Bonus\")\n",
    "plt.title(\"Scatterplot of salary & bonus\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## So I removed the NaN values too, it's another outlier. Does it have to be visualized aswell?\n",
    "\n",
    "# Removing the NaN values:\n",
    "enron_dataf.replace(to_replace= 'NaN', value= 0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRETSFBRERCRNQUFERNL+P8wtrcbX2/1eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xce56198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let't eliminate the 'Total' counts!\n",
    "# The plot brought a more comprehensive view\n",
    "\n",
    "\n",
    "enron_dataf.drop('TOTAL', axis = 0, inplace = True)\n",
    "\n",
    "plt.scatter(enron_dataf[\"salary\"][enron_dataf[\"poi\"] == True],enron_dataf[\"bonus\"][enron_dataf[\"poi\"] == True], color = 'r',\n",
    "           label = \"POI\")\n",
    "plt.scatter(enron_dataf[\"salary\"][enron_dataf[\"poi\"] == False],enron_dataf[\"bonus\"][enron_dataf[\"poi\"] == False],color = 'b',\n",
    "           label = \"Not-POI\")\n",
    "    \n",
    "plt.xlabel(\"Salary\")\n",
    "plt.ylabel(\"Bonus\")\n",
    "plt.title(\"Scatterplot of salary & bonus after removing outliers\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean all 'inf' values which we got if the person's from_messages = 0 o co z tym chodzi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#enron_df_new = enron_df_new.replace('inf', 0) enron_df_new = enron_df_new.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### FEATURES\n",
    "#2. Feature processing of the dataset about ENRON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## My features still don't work :(\n",
    "\n",
    "# Created two new features in ratios:\n",
    "enron_dataf['new_feature_from_meassages_to_poi_ratio'] = enron_dataf['from_messages']/enron_dataf['from_poi_to_this_person']\n",
    "enron_dataf['new_feature_to_messages_from_this_person_to_poi_ratio'] = enron_dataf['to_messages']/enron_dataf['from_this_person_to_poi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-0637936b1aca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#add our new features to the features list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeatures_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'new_feature_from_meassages_to_poi_ratio'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfeatures_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'new_feature_to_messages_from_this_person_to_poi_ratio'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features_list' is not defined"
     ]
    }
   ],
   "source": [
    "#add our new features to the features list\n",
    "features_list.append('new_feature_from_meassages_to_poi_ratio')\n",
    "features_list.append('new_feature_to_messages_from_this_person_to_poi_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## So I removed the NaN values too, it's another outlier. Does it have to be visualized aswell? pozmieniaj to kobitko\n",
    "\n",
    "# Removing the NaN values:\n",
    "enron_dataf.replace(to_replace= \"NaN\", value= 0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['TOTAL'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0a548d52b952>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menron_dataf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TOTAL'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2048\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2050\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2051\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexes\\base.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3573\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3574\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3575\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3576\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3577\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['TOTAL'] not contained in axis"
     ]
    }
   ],
   "source": [
    "enron_dataf.drop('TOTAL', axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enron_dataf = enron_dataf.replace('NaN', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enron_dataf = enron_dataf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enron_dataf.replace(to_replace = 'inf', value= 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enron_dataf = enron_dataf.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bonus                                                    float64\n",
       "deferral_payments                                        float64\n",
       "deferred_income                                          float64\n",
       "director_fees                                            float64\n",
       "email_address                                            float64\n",
       "exercised_stock_options                                  float64\n",
       "expenses                                                 float64\n",
       "from_messages                                            float64\n",
       "from_poi_to_this_person                                  float64\n",
       "from_this_person_to_poi                                  float64\n",
       "loan_advances                                            float64\n",
       "long_term_incentive                                      float64\n",
       "other                                                    float64\n",
       "poi                                                      float64\n",
       "restricted_stock                                         float64\n",
       "restricted_stock_deferred                                float64\n",
       "salary                                                   float64\n",
       "shared_receipt_with_poi                                  float64\n",
       "to_messages                                              float64\n",
       "total_payments                                           float64\n",
       "total_stock_value                                        float64\n",
       "new_feature_from_meassages_to_poi_ratio                  float64\n",
       "new_feature_to_messages_from_this_person_to_poi_ratio    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_dataf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.py:3675: UserWarning: the \"axis\" argument is deprecated and will be removed inv0.13; this argument has no effect\n",
      "  warn('the \"axis\" argument is deprecated and will be removed in'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot replace ['THE TRAVEL AGENCY IN THE PARK'] with method pad on a DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-27fb822efd46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# Deleting the row with index 'THE TRAVEL AGENCY IN THE PARK'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menron_dataf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_replace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'THE TRAVEL AGENCY IN THE PARK'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method, axis)\u001b[0m\n\u001b[1;32m   3686\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3687\u001b[0m                 return _single_replace(self, to_replace, method, inplace,\n\u001b[0;32m-> 3688\u001b[0;31m                                        limit)\n\u001b[0m\u001b[1;32m   3689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3690\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_single_replace\u001b[0;34m(self, to_replace, method, inplace, limit)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         raise TypeError('cannot replace {0} with method {1} on a {2}'\n\u001b[0;32m---> 73\u001b[0;31m                         .format(to_replace, method, type(self).__name__))\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0morig_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot replace ['THE TRAVEL AGENCY IN THE PARK'] with method pad on a DataFrame"
     ]
    }
   ],
   "source": [
    "# Deleting the row with index 'THE TRAVEL AGENCY IN THE PARK'\n",
    "enron_dataf.replace(to_replace = 'THE TRAVEL AGENCY IN THE PARK', axis = 0, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enron_dataf.drop('email_address', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Deleting the row with index 'THE TRAVEL AGENCY IN THE PARK'\n",
    "enron_dataf.drop('THE TRAVEL AGENCY IN THE PARK', axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>...</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>new_feature_from_meassages_to_poi_ratio</th>\n",
       "      <th>new_feature_to_messages_from_this_person_to_poi_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94299.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>585062.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365788.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>1061827.0</td>\n",
       "      <td>585062.0</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>267102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>10623258.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <td>350000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-400729.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4890344.0</td>\n",
       "      <td>78552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1788391.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170941.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211725.0</td>\n",
       "      <td>6678735.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>651850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>386335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1038185.0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <td>1500000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3117011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5538001.0</td>\n",
       "      <td>34039.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>853064.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243293.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>288682.0</td>\n",
       "      <td>6391065.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.761905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      bonus  deferral_payments  deferred_income  \\\n",
       "METTS MARK         600000.0                0.0              0.0   \n",
       "BAXTER JOHN C     1200000.0          1295738.0       -1386055.0   \n",
       "ELLIOTT STEVEN     350000.0                0.0        -400729.0   \n",
       "CORDES WILLIAM R        0.0                0.0              0.0   \n",
       "HANNON KEVIN P    1500000.0                0.0       -3117011.0   \n",
       "\n",
       "                  director_fees  exercised_stock_options  expenses  \\\n",
       "METTS MARK                  0.0                      0.0   94299.0   \n",
       "BAXTER JOHN C               0.0                6680544.0   11200.0   \n",
       "ELLIOTT STEVEN              0.0                4890344.0   78552.0   \n",
       "CORDES WILLIAM R            0.0                 651850.0       0.0   \n",
       "HANNON KEVIN P              0.0                5538001.0   34039.0   \n",
       "\n",
       "                  from_messages  from_poi_to_this_person  \\\n",
       "METTS MARK                 29.0                     38.0   \n",
       "BAXTER JOHN C               0.0                      0.0   \n",
       "ELLIOTT STEVEN              0.0                      0.0   \n",
       "CORDES WILLIAM R           12.0                     10.0   \n",
       "HANNON KEVIN P             32.0                     32.0   \n",
       "\n",
       "                  from_this_person_to_poi  loan_advances  \\\n",
       "METTS MARK                            1.0            0.0   \n",
       "BAXTER JOHN C                         0.0            0.0   \n",
       "ELLIOTT STEVEN                        0.0            0.0   \n",
       "CORDES WILLIAM R                      0.0            0.0   \n",
       "HANNON KEVIN P                       21.0            0.0   \n",
       "\n",
       "                                          ...                            poi  \\\n",
       "METTS MARK                                ...                            0.0   \n",
       "BAXTER JOHN C                             ...                            0.0   \n",
       "ELLIOTT STEVEN                            ...                            0.0   \n",
       "CORDES WILLIAM R                          ...                            0.0   \n",
       "HANNON KEVIN P                            ...                            1.0   \n",
       "\n",
       "                  restricted_stock  restricted_stock_deferred    salary  \\\n",
       "METTS MARK                585062.0                        0.0  365788.0   \n",
       "BAXTER JOHN C            3942714.0                        0.0  267102.0   \n",
       "ELLIOTT STEVEN           1788391.0                        0.0  170941.0   \n",
       "CORDES WILLIAM R          386335.0                        0.0       0.0   \n",
       "HANNON KEVIN P            853064.0                        0.0  243293.0   \n",
       "\n",
       "                  shared_receipt_with_poi  to_messages  total_payments  \\\n",
       "METTS MARK                          702.0        807.0       1061827.0   \n",
       "BAXTER JOHN C                         0.0          0.0       5634343.0   \n",
       "ELLIOTT STEVEN                        0.0          0.0        211725.0   \n",
       "CORDES WILLIAM R                     58.0        764.0             0.0   \n",
       "HANNON KEVIN P                     1035.0       1045.0        288682.0   \n",
       "\n",
       "                  total_stock_value  new_feature_from_meassages_to_poi_ratio  \\\n",
       "METTS MARK                 585062.0                                 0.763158   \n",
       "BAXTER JOHN C            10623258.0                                 0.000000   \n",
       "ELLIOTT STEVEN            6678735.0                                 0.000000   \n",
       "CORDES WILLIAM R          1038185.0                                 1.200000   \n",
       "HANNON KEVIN P            6391065.0                                 1.000000   \n",
       "\n",
       "                  new_feature_to_messages_from_this_person_to_poi_ratio  \n",
       "METTS MARK                                               807.000000      \n",
       "BAXTER JOHN C                                              0.000000      \n",
       "ELLIOTT STEVEN                                             0.000000      \n",
       "CORDES WILLIAM R                                                inf      \n",
       "HANNON KEVIN P                                            49.761905      \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_dataf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Converting the above modified dataframe to a dictionary\n",
    "enron_dict = enron_dataf.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To make it easier with further exploration let's set my dataset to a dataset\n",
    "# MY DATASET czy co to ma byc?\n",
    "my_dataset = enron_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# enron_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's focus on choosing the features to indentify a POI\n",
    "# I will use only the provided features, POI, financial and email as per below:\n",
    "\n",
    "# POI\n",
    "\n",
    "# Features with email: 'from_messages', 'shared_receipt_with_poi',['fraction_mail_from_poi', 'fraction_mail_to_poi', 'from_poi_to_this_person', 'from_this_person_to_poi', 'to_messages', 'from_messages']\n",
    "\n",
    "# Financial features: ['poi', 'salary', 'bonus','deferral_payments', 'expenses', \n",
    "#                 'restricted_stock_deferred', 'restricted_stock', 'deferred_income','total_payments',\n",
    "#                 'exercised_stock_options', 'total_stock_value', 'restricted_stock']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = ['poi', 'salary', 'bonus', 'deferral_payments', 'expenses', \n",
    "                 'deferred_income','total_payments',\n",
    "                 'from_poi_to_this_person', 'from_this_person_to_poi', 'to_messages', \n",
    "                 'from_messages', 'shared_receipt_with_poi', 'exercised_stock_options',\n",
    "                'total_stock_value', 'new_feature_from_meassages_to_poi_ratio', \n",
    "                'new_feature_to_messages_from_this_person_to_poi_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_dict = pickle.load(open(\"my_dataset.pkl\", \"r\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# zmien to tez prosze\n",
    "# I mus split data into training and testing datasets to run classifiers\n",
    "\n",
    "from sklearn import cross_validation\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels, test_size=0.3, \n",
    "                                                                                             random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-167de13456a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;31m#zobacz czy mozna zmienic nazwe tego accuracy score i skad sie to wzielo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\naive_bayes.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \"\"\"\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m    184\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "## I don't understand why, but yesterday it was all working! Could it be because of the dataframe instead of diciotnary?\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "t0 = time()\n",
    "#zobacz czy mozna zmienic nazwe tego accuracy score i skad sie to wzielo\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "prediction = clf.predict(features_test)\n",
    "accuracy = accuracy_score(labels_test, prediction)\n",
    "\n",
    "\n",
    "print \"Accuracy for GaussianNB:\", accuracy\n",
    "\n",
    "print \"GaussianNB time of running algorithm:\", round(time()-t0, 3), \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-1106d9761a1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "## I don't understand why, but yesterday it was all working! Could it be because of the dataframe instead of diciotnary?\n",
    "\n",
    "# Another classifer is a Decision Tree,\n",
    "# it gives certainly bigger accuracy\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# jak cos to to teraz dodalam wieczorem\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train,labels_train)\n",
    "score = clf.score(features_test,labels_test)\n",
    "pred= clf.predict(features_test)\n",
    "print 'accuracy', score\n",
    "\n",
    "print \"Decision tree algorithm time:\", round(time()-t0, 3), \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-77577de2e6f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 512\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-fe8c79033653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"testing time: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"s\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "## I don't understand why, but yesterday it was all working! Could it be because of the dataframe instead of diciotnary?\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "clf.fit(features_train, labels_train)\n",
    "prediction = clf.predict(features_test)\n",
    "print \"testing time: \", round(time()-t0, 3), \"s\"\n",
    "print \"Accuracy of DT classifer is  : \",accuracy_score(labels_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-f594c40be101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"testing time: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"s\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "\n",
    "clf.fit(features_train, labels_train)\n",
    "prediction = clf.predict(features_test)\n",
    "print \"testing time: \", round(time()-t0, 3), \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Accuracy can be interpreted as : 85.2% predictions on the total test set have been made correctly.\n",
    "\n",
    "#Precision can be interpreted as : if a person is being classified as a POI by my classifier then there is a 47.6% chance that the person is actually a POI. (i.e., a 47.6% chance of obtaining a true positive condition.)\n",
    "\n",
    "#Recall can be interpreted as : of all the actual POIs considered, 37.7% of all the POIs can be classified correctly as a POI by my classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create final classifer/ czy to mialoby sens?\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_features=2, min_samples_split=2,\n",
    "                             criterion='entropy', max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to bylo po prostu to \n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With 146 Enron employers, 18 of which are POIs, the dataset used is both small and is imbalanced. zmien to jakos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration                   Training set observations                   Testing set observations\n",
      "    1     [ 5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]        [0 1 2 3 4]       \n",
      "    2     [ 0  1  2  3  4 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]        [5 6 7 8 9]       \n",
      "    3     [ 0  1  2  3  4  5  6  7  8  9 15 16 17 18 19 20 21 22 23 24]     [10 11 12 13 14]     \n",
      "    4     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 20 21 22 23 24]     [15 16 17 18 19]     \n",
      "    5     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]     [20 21 22 23 24]     \n"
     ]
    }
   ],
   "source": [
    "# moze to potem do validacji?? chyba raczej trzeba uzyc tego pipeline czy cos\n",
    "# simulate splitting a dataset of 25 observations into 5 folds\n",
    "from sklearn.cross_validation import KFold\n",
    "kf = KFold(25, n_folds=5, shuffle=False)\n",
    "\n",
    "# print the contents of each training and testing set\n",
    "print('{} {:^61} {}'.format('Iteration', 'Training set observations', 'Testing set observations'))\n",
    "for iteration, data in enumerate(kf, start=1):\n",
    "    print('{:^9} {} {:^25}'.format(iteration, data[0], data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
