{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Identify fraud from Enron Email\n",
    "\n",
    "### Enron became a symbol for fraud \n",
    "# The spectacular collapse of a giant american company in electric field was not only an end to the company\n",
    "# but brought also a massive change for the american and global economy. \n",
    "# In 2001 Enron announced results for 3rd quarter and at the same time to a big surprise of shareholders a banckruptacy.\n",
    "# In this project I'd like to focus on the most influencial workers of Enron which are obviously involved in the fraud.\n",
    "# The most famous is CEO Jeffrey Keith \"Jeff\" Skilling and a chairman  Kenneth Lay of Enron \n",
    "# during most of the time when the crime occured.\n",
    "# We will see their salaries, bonuses and stocks which are quite interesting.\n",
    "# \n",
    "\n",
    "# Going through given dataset with e-mails within Enron co-workers we will discover a POI - Person of Interest,\n",
    "# basically a person suspected to participate in the fraud.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Firstly, let's load the necessary data and packages. \n",
    "# I am going to create a dataframe in pandas and then with the use of numpy arrays and matplotlib visualize it.\n",
    "# To further analysis in classyfing will need Sklearn, GaussianNB,... i co jeszcze?\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "import random\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "import pandas as pd\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "### Let's load my dictionary providede by Udacity\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the type of my dataset, as we see it's a dictionary\n",
    "type(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-204ca7876cc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "numpy.isinf\n",
    "\n",
    "np.isinf(np.inf)\n",
    "\n",
    "np.isinf(np.nan)\n",
    "\n",
    "np.isinf(np.NINF)\n",
    "\n",
    "np.isinf([np.inf, -np.inf, 1.0, np.nan])\n",
    "array([ True,  True, False, False], dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# By converting the dictionary to a dataframe with pandas it will be easier and faster to work with it:\n",
    "enron_dataf = pd.DataFrame.from_records(list(data_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mark.metts@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94299</td>\n",
       "      <td>29</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1740</td>\n",
       "      <td>False</td>\n",
       "      <td>585062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365788</td>\n",
       "      <td>702</td>\n",
       "      <td>807</td>\n",
       "      <td>1061827</td>\n",
       "      <td>585062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>1200000</td>\n",
       "      <td>1295738</td>\n",
       "      <td>-1386055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6680544</td>\n",
       "      <td>11200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1586055</td>\n",
       "      <td>2660303</td>\n",
       "      <td>False</td>\n",
       "      <td>3942714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5634343</td>\n",
       "      <td>10623258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <td>350000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-400729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>steven.elliott@enron.com</td>\n",
       "      <td>4890344</td>\n",
       "      <td>78552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12961</td>\n",
       "      <td>False</td>\n",
       "      <td>1788391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211725</td>\n",
       "      <td>6678735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bill.cordes@enron.com</td>\n",
       "      <td>651850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>386335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1038185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <td>1500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3117011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kevin.hannon@enron.com</td>\n",
       "      <td>5538001</td>\n",
       "      <td>34039</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>1617011</td>\n",
       "      <td>11350</td>\n",
       "      <td>True</td>\n",
       "      <td>853064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>243293</td>\n",
       "      <td>1035</td>\n",
       "      <td>1045</td>\n",
       "      <td>288682</td>\n",
       "      <td>6391065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    bonus deferral_payments deferred_income director_fees  \\\n",
       "METTS MARK         600000               NaN             NaN           NaN   \n",
       "BAXTER JOHN C     1200000           1295738        -1386055           NaN   \n",
       "ELLIOTT STEVEN     350000               NaN         -400729           NaN   \n",
       "CORDES WILLIAM R      NaN               NaN             NaN           NaN   \n",
       "HANNON KEVIN P    1500000               NaN        -3117011           NaN   \n",
       "\n",
       "                             email_address exercised_stock_options expenses  \\\n",
       "METTS MARK            mark.metts@enron.com                     NaN    94299   \n",
       "BAXTER JOHN C                          NaN                 6680544    11200   \n",
       "ELLIOTT STEVEN    steven.elliott@enron.com                 4890344    78552   \n",
       "CORDES WILLIAM R     bill.cordes@enron.com                  651850      NaN   \n",
       "HANNON KEVIN P      kevin.hannon@enron.com                 5538001    34039   \n",
       "\n",
       "                 from_messages from_poi_to_this_person  \\\n",
       "METTS MARK                  29                      38   \n",
       "BAXTER JOHN C              NaN                     NaN   \n",
       "ELLIOTT STEVEN             NaN                     NaN   \n",
       "CORDES WILLIAM R            12                      10   \n",
       "HANNON KEVIN P              32                      32   \n",
       "\n",
       "                 from_this_person_to_poi        ...         \\\n",
       "METTS MARK                             1        ...          \n",
       "BAXTER JOHN C                        NaN        ...          \n",
       "ELLIOTT STEVEN                       NaN        ...          \n",
       "CORDES WILLIAM R                       0        ...          \n",
       "HANNON KEVIN P                        21        ...          \n",
       "\n",
       "                 long_term_incentive    other    poi  restricted_stock  \\\n",
       "METTS MARK                       NaN     1740  False            585062   \n",
       "BAXTER JOHN C                1586055  2660303  False           3942714   \n",
       "ELLIOTT STEVEN                   NaN    12961  False           1788391   \n",
       "CORDES WILLIAM R                 NaN      NaN  False            386335   \n",
       "HANNON KEVIN P               1617011    11350   True            853064   \n",
       "\n",
       "                 restricted_stock_deferred  salary shared_receipt_with_poi  \\\n",
       "METTS MARK                             NaN  365788                     702   \n",
       "BAXTER JOHN C                          NaN  267102                     NaN   \n",
       "ELLIOTT STEVEN                         NaN  170941                     NaN   \n",
       "CORDES WILLIAM R                       NaN     NaN                      58   \n",
       "HANNON KEVIN P                         NaN  243293                    1035   \n",
       "\n",
       "                 to_messages total_payments total_stock_value  \n",
       "METTS MARK               807        1061827            585062  \n",
       "BAXTER JOHN C            NaN        5634343          10623258  \n",
       "ELLIOTT STEVEN           NaN         211725           6678735  \n",
       "CORDES WILLIAM R         764            NaN           1038185  \n",
       "HANNON KEVIN P          1045         288682           6391065  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previosly the index were numbers, but it's easier to set them as names of employees series:\n",
    "employees = pd.Series(list(data_dict.keys()))\n",
    "enron_dataf.set_index(employees, inplace=True)\n",
    "enron_dataf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94299.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>False</td>\n",
       "      <td>585062.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365788.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>1061827.0</td>\n",
       "      <td>585062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1586055.0</td>\n",
       "      <td>2660303.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>267102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>10623258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <td>350000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-400729.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4890344.0</td>\n",
       "      <td>78552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12961.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1788391.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170941.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211725.0</td>\n",
       "      <td>6678735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>651850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>386335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1038185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <td>1500000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3117011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5538001.0</td>\n",
       "      <td>34039.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1617011.0</td>\n",
       "      <td>11350.0</td>\n",
       "      <td>True</td>\n",
       "      <td>853064.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243293.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>288682.0</td>\n",
       "      <td>6391065.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      bonus  deferral_payments  deferred_income  \\\n",
       "METTS MARK         600000.0                0.0              0.0   \n",
       "BAXTER JOHN C     1200000.0          1295738.0       -1386055.0   \n",
       "ELLIOTT STEVEN     350000.0                0.0        -400729.0   \n",
       "CORDES WILLIAM R        0.0                0.0              0.0   \n",
       "HANNON KEVIN P    1500000.0                0.0       -3117011.0   \n",
       "\n",
       "                  director_fees  email_address  exercised_stock_options  \\\n",
       "METTS MARK                  0.0            0.0                      0.0   \n",
       "BAXTER JOHN C               0.0            0.0                6680544.0   \n",
       "ELLIOTT STEVEN              0.0            0.0                4890344.0   \n",
       "CORDES WILLIAM R            0.0            0.0                 651850.0   \n",
       "HANNON KEVIN P              0.0            0.0                5538001.0   \n",
       "\n",
       "                  expenses  from_messages  from_poi_to_this_person  \\\n",
       "METTS MARK         94299.0           29.0                     38.0   \n",
       "BAXTER JOHN C      11200.0            0.0                      0.0   \n",
       "ELLIOTT STEVEN     78552.0            0.0                      0.0   \n",
       "CORDES WILLIAM R       0.0           12.0                     10.0   \n",
       "HANNON KEVIN P     34039.0           32.0                     32.0   \n",
       "\n",
       "                  from_this_person_to_poi        ...          \\\n",
       "METTS MARK                            1.0        ...           \n",
       "BAXTER JOHN C                         0.0        ...           \n",
       "ELLIOTT STEVEN                        0.0        ...           \n",
       "CORDES WILLIAM R                      0.0        ...           \n",
       "HANNON KEVIN P                       21.0        ...           \n",
       "\n",
       "                  long_term_incentive      other    poi  restricted_stock  \\\n",
       "METTS MARK                        0.0     1740.0  False          585062.0   \n",
       "BAXTER JOHN C               1586055.0  2660303.0  False         3942714.0   \n",
       "ELLIOTT STEVEN                    0.0    12961.0  False         1788391.0   \n",
       "CORDES WILLIAM R                  0.0        0.0  False          386335.0   \n",
       "HANNON KEVIN P              1617011.0    11350.0   True          853064.0   \n",
       "\n",
       "                  restricted_stock_deferred    salary  \\\n",
       "METTS MARK                              0.0  365788.0   \n",
       "BAXTER JOHN C                           0.0  267102.0   \n",
       "ELLIOTT STEVEN                          0.0  170941.0   \n",
       "CORDES WILLIAM R                        0.0       0.0   \n",
       "HANNON KEVIN P                          0.0  243293.0   \n",
       "\n",
       "                  shared_receipt_with_poi  to_messages  total_payments  \\\n",
       "METTS MARK                          702.0        807.0       1061827.0   \n",
       "BAXTER JOHN C                         0.0          0.0       5634343.0   \n",
       "ELLIOTT STEVEN                        0.0          0.0        211725.0   \n",
       "CORDES WILLIAM R                     58.0        764.0             0.0   \n",
       "HANNON KEVIN P                     1035.0       1045.0        288682.0   \n",
       "\n",
       "                  total_stock_value  \n",
       "METTS MARK                 585062.0  \n",
       "BAXTER JOHN C            10623258.0  \n",
       "ELLIOTT STEVEN            6678735.0  \n",
       "CORDES WILLIAM R          1038185.0  \n",
       "HANNON KEVIN P            6391065.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coerce numeric values into floats or ints; also change NaN to zero:\n",
    "enron_dataf = enron_dataf.apply(lambda x : pd.to_numeric(x, errors = 'coerce')).copy().fillna(0)\n",
    "enron_dataf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94299.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>False</td>\n",
       "      <td>585062.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365788.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>1061827.0</td>\n",
       "      <td>585062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1586055.0</td>\n",
       "      <td>2660303.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>267102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>10623258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <td>350000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-400729.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4890344.0</td>\n",
       "      <td>78552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12961.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1788391.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170941.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211725.0</td>\n",
       "      <td>6678735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>651850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>386335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1038185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <td>1500000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3117011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5538001.0</td>\n",
       "      <td>34039.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1617011.0</td>\n",
       "      <td>11350.0</td>\n",
       "      <td>True</td>\n",
       "      <td>853064.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243293.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>288682.0</td>\n",
       "      <td>6391065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MORDAUNT KRISTINA M</th>\n",
       "      <td>325000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35018.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>False</td>\n",
       "      <td>208510.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>267093.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>628522.0</td>\n",
       "      <td>208510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEYER ROCKFORD G</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1848227.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>493489.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>462384.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>1848227.0</td>\n",
       "      <td>955873.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCMAHON JEFFREY</th>\n",
       "      <td>2600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1104054.0</td>\n",
       "      <td>137108.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>694862.0</td>\n",
       "      <td>297353.0</td>\n",
       "      <td>False</td>\n",
       "      <td>558801.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370448.0</td>\n",
       "      <td>2228.0</td>\n",
       "      <td>2355.0</td>\n",
       "      <td>4099771.0</td>\n",
       "      <td>1662855.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HORTON STANLEY C</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3131860.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5210569.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2046079.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>2350.0</td>\n",
       "      <td>3131860.0</td>\n",
       "      <td>7256648.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIPER GREGORY F</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>1130036.0</td>\n",
       "      <td>-33333.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>880290.0</td>\n",
       "      <td>43057.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>778.0</td>\n",
       "      <td>False</td>\n",
       "      <td>409554.0</td>\n",
       "      <td>-409554.0</td>\n",
       "      <td>197091.0</td>\n",
       "      <td>742.0</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>1737629.0</td>\n",
       "      <td>880290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUMPHREY GENE E</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2964506.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2282768.0</td>\n",
       "      <td>4994.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130724.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3100224.0</td>\n",
       "      <td>2282768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMANOFF ADAM S</th>\n",
       "      <td>788750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53122.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288589.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1130461.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACHMAN JEREMY M</th>\n",
       "      <td>850000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>765313.0</td>\n",
       "      <td>84208.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>831809.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>False</td>\n",
       "      <td>189041.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248546.0</td>\n",
       "      <td>2326.0</td>\n",
       "      <td>2475.0</td>\n",
       "      <td>2014835.0</td>\n",
       "      <td>954354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUNDE MARTIN</th>\n",
       "      <td>700000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>476451.0</td>\n",
       "      <td>111122.0</td>\n",
       "      <td>False</td>\n",
       "      <td>698920.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>257486.0</td>\n",
       "      <td>2565.0</td>\n",
       "      <td>2647.0</td>\n",
       "      <td>1545059.0</td>\n",
       "      <td>698920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GIBBS DANA R</th>\n",
       "      <td>0.0</td>\n",
       "      <td>504610.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2218275.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461912.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>966522.0</td>\n",
       "      <td>2218275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOWRY CHARLES P</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>153686.0</td>\n",
       "      <td>-153686.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLWELL WESLEY</th>\n",
       "      <td>1200000.0</td>\n",
       "      <td>27610.0</td>\n",
       "      <td>-144062.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16514.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101740.0</td>\n",
       "      <td>True</td>\n",
       "      <td>698242.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288542.0</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>1758.0</td>\n",
       "      <td>1490344.0</td>\n",
       "      <td>698242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MULLER MARK S</th>\n",
       "      <td>1100000.0</td>\n",
       "      <td>842924.0</td>\n",
       "      <td>-719000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1056320.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1725545.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>False</td>\n",
       "      <td>360528.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>251654.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>3202070.0</td>\n",
       "      <td>1416848.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JACKSON CHARLENE R</th>\n",
       "      <td>250000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185063.0</td>\n",
       "      <td>10181.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2435.0</td>\n",
       "      <td>False</td>\n",
       "      <td>540672.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288558.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>551174.0</td>\n",
       "      <td>725735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WESTFAHL RICHARD K</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51870.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256191.0</td>\n",
       "      <td>401130.0</td>\n",
       "      <td>False</td>\n",
       "      <td>384930.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63744.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>762135.0</td>\n",
       "      <td>384930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALTERS GARETH W</th>\n",
       "      <td>0.0</td>\n",
       "      <td>53625.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1030329.0</td>\n",
       "      <td>33785.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87410.0</td>\n",
       "      <td>1030329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALLS JR ROBERT H</th>\n",
       "      <td>850000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4346544.0</td>\n",
       "      <td>50936.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540751.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1552453.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>357091.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>1798780.0</td>\n",
       "      <td>5898997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KITCHEN LOUISE</th>\n",
       "      <td>3100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81042.0</td>\n",
       "      <td>5774.0</td>\n",
       "      <td>1728.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93925.0</td>\n",
       "      <td>False</td>\n",
       "      <td>466101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271442.0</td>\n",
       "      <td>3669.0</td>\n",
       "      <td>8305.0</td>\n",
       "      <td>3471141.0</td>\n",
       "      <td>547143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAN RONNIE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-98784.0</td>\n",
       "      <td>98784.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>32460.0</td>\n",
       "      <td>-32460.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BELFER ROBERT</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-102500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44093.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102500.0</td>\n",
       "      <td>-44093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHANKMAN JEFFREY A</th>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1441898.0</td>\n",
       "      <td>178979.0</td>\n",
       "      <td>2681.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>554422.0</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>False</td>\n",
       "      <td>630137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304110.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>3221.0</td>\n",
       "      <td>3038702.0</td>\n",
       "      <td>2072035.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WODRASKA JOHN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189583.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189583.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERGSIEKER RICHARD P</th>\n",
       "      <td>250000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-485813.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59175.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180250.0</td>\n",
       "      <td>427316.0</td>\n",
       "      <td>False</td>\n",
       "      <td>659249.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187922.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>618850.0</td>\n",
       "      <td>659249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URQUHART JOHN A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-36666.0</td>\n",
       "      <td>36666.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228656.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228656.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIBI PHILIPPE A</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1465734.0</td>\n",
       "      <td>38559.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>369721.0</td>\n",
       "      <td>425688.0</td>\n",
       "      <td>False</td>\n",
       "      <td>378082.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213625.0</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>2047593.0</td>\n",
       "      <td>1843816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REYNOLDS LAWRENCE</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>51365.0</td>\n",
       "      <td>-200000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4160672.0</td>\n",
       "      <td>8409.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156250.0</td>\n",
       "      <td>202052.0</td>\n",
       "      <td>False</td>\n",
       "      <td>201483.0</td>\n",
       "      <td>-140264.0</td>\n",
       "      <td>76399.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>394475.0</td>\n",
       "      <td>4221891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIMICHELE RICHARD G</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8191755.0</td>\n",
       "      <td>35812.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>694862.0</td>\n",
       "      <td>374689.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126027.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>262788.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2368151.0</td>\n",
       "      <td>8317782.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>2604490.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-2604490.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARTER REBECCA C</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-159792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>False</td>\n",
       "      <td>307301.0</td>\n",
       "      <td>-307301.0</td>\n",
       "      <td>261809.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>477557.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUCHANAN HAROLD G</th>\n",
       "      <td>500000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>825464.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304805.0</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>False</td>\n",
       "      <td>189041.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248017.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>1054637.0</td>\n",
       "      <td>1014505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAP SOON</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192758.0</td>\n",
       "      <td>55097.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55097.0</td>\n",
       "      <td>192758.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MURRAY JULIA H</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400478.0</td>\n",
       "      <td>57580.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>False</td>\n",
       "      <td>196983.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229284.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>2192.0</td>\n",
       "      <td>812194.0</td>\n",
       "      <td>597461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GARLAND C KEVIN</th>\n",
       "      <td>850000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>636246.0</td>\n",
       "      <td>48405.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>375304.0</td>\n",
       "      <td>60814.0</td>\n",
       "      <td>False</td>\n",
       "      <td>259907.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231946.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>1566469.0</td>\n",
       "      <td>896153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DODSON KEITH</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28164.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>774.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221003.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>319941.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAGER F SCOTT</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8308552.0</td>\n",
       "      <td>53947.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147950.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3576206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158403.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360300.0</td>\n",
       "      <td>11884758.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HIRKO JOSEPH</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10259.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30766064.0</td>\n",
       "      <td>77978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2856.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91093.0</td>\n",
       "      <td>30766064.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIETRICH JANET R</th>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1550019.0</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>556416.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>False</td>\n",
       "      <td>315068.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250100.0</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>2572.0</td>\n",
       "      <td>1410464.0</td>\n",
       "      <td>1865087.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DERRICK JR. JAMES V</th>\n",
       "      <td>800000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1284000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8831913.0</td>\n",
       "      <td>51124.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>484000.0</td>\n",
       "      <td>7482.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1787380.0</td>\n",
       "      <td>-1787380.0</td>\n",
       "      <td>492375.0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>2181.0</td>\n",
       "      <td>550981.0</td>\n",
       "      <td>8831913.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FREVERT MARK A</th>\n",
       "      <td>2000000.0</td>\n",
       "      <td>6426990.0</td>\n",
       "      <td>-3367011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10433518.0</td>\n",
       "      <td>86987.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>1617011.0</td>\n",
       "      <td>7427621.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4188667.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1060932.0</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>3275.0</td>\n",
       "      <td>17252530.0</td>\n",
       "      <td>14622185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAI LOU L</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15364167.0</td>\n",
       "      <td>32047.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1829457.0</td>\n",
       "      <td>False</td>\n",
       "      <td>8453763.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261879.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3123383.0</td>\n",
       "      <td>23817930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAY FRANKLIN R</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>260455.0</td>\n",
       "      <td>-201641.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129142.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>False</td>\n",
       "      <td>145796.0</td>\n",
       "      <td>-82782.0</td>\n",
       "      <td>239671.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>827696.0</td>\n",
       "      <td>63014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAYSLETT RODERICK J</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>346663.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>2649.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>346663.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FUGH JOHN L</th>\n",
       "      <td>0.0</td>\n",
       "      <td>50591.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176378.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50591.0</td>\n",
       "      <td>176378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FALLON JAMES B</th>\n",
       "      <td>2500000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>940257.0</td>\n",
       "      <td>95924.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>374347.0</td>\n",
       "      <td>401481.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1392142.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304588.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>3676340.0</td>\n",
       "      <td>2332399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KOENIG MARK E</th>\n",
       "      <td>700000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>671737.0</td>\n",
       "      <td>127017.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>150458.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1248318.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>309946.0</td>\n",
       "      <td>2271.0</td>\n",
       "      <td>2374.0</td>\n",
       "      <td>1587421.0</td>\n",
       "      <td>1920055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAVAGE FRANK</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-121284.0</td>\n",
       "      <td>125034.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IZZO LAWRENCE L</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2165172.0</td>\n",
       "      <td>28093.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>312500.0</td>\n",
       "      <td>1553729.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3654808.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85274.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>1979596.0</td>\n",
       "      <td>5819980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TILNEY ELIZABETH A</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-575000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>591250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>152055.0</td>\n",
       "      <td>False</td>\n",
       "      <td>576792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>247338.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>399393.0</td>\n",
       "      <td>1168042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARTIN AMANDA K</th>\n",
       "      <td>0.0</td>\n",
       "      <td>85430.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2070306.0</td>\n",
       "      <td>8211.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5145434.0</td>\n",
       "      <td>2818454.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349487.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>8407016.0</td>\n",
       "      <td>2070306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY RICHARD B</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>649584.0</td>\n",
       "      <td>-694862.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2542813.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>769862.0</td>\n",
       "      <td>400572.0</td>\n",
       "      <td>False</td>\n",
       "      <td>901657.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330546.0</td>\n",
       "      <td>2333.0</td>\n",
       "      <td>3523.0</td>\n",
       "      <td>2355702.0</td>\n",
       "      <td>3444470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRAMM WENDY L</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119292.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119292.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAUSEY RICHARD A</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-235000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30674.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>307895.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2502063.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>415189.0</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1868758.0</td>\n",
       "      <td>2502063.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAYLOR MITCHELL S</th>\n",
       "      <td>600000.0</td>\n",
       "      <td>227449.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3181250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>563798.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>265214.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>1092663.0</td>\n",
       "      <td>3745048.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DONAHUE JR JEFFREY M</th>\n",
       "      <td>800000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-300000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>765920.0</td>\n",
       "      <td>96268.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>False</td>\n",
       "      <td>315068.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278601.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>875760.0</td>\n",
       "      <td>1080988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLISAN JR BEN F</th>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>384728.0</td>\n",
       "      <td>125978.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71023.0</td>\n",
       "      <td>200308.0</td>\n",
       "      <td>True</td>\n",
       "      <td>393818.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274975.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>1272284.0</td>\n",
       "      <td>778546.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          bonus  deferral_payments  deferred_income  \\\n",
       "METTS MARK             600000.0                0.0              0.0   \n",
       "BAXTER JOHN C         1200000.0          1295738.0       -1386055.0   \n",
       "ELLIOTT STEVEN         350000.0                0.0        -400729.0   \n",
       "CORDES WILLIAM R            0.0                0.0              0.0   \n",
       "HANNON KEVIN P        1500000.0                0.0       -3117011.0   \n",
       "MORDAUNT KRISTINA M    325000.0                0.0              0.0   \n",
       "MEYER ROCKFORD G            0.0          1848227.0              0.0   \n",
       "MCMAHON JEFFREY       2600000.0                0.0              0.0   \n",
       "HORTON STANLEY C            0.0          3131860.0              0.0   \n",
       "PIPER GREGORY F        400000.0          1130036.0         -33333.0   \n",
       "HUMPHREY GENE E             0.0          2964506.0              0.0   \n",
       "UMANOFF ADAM S         788750.0                0.0              0.0   \n",
       "BLACHMAN JEREMY M      850000.0                0.0              0.0   \n",
       "SUNDE MARTIN           700000.0                0.0              0.0   \n",
       "GIBBS DANA R                0.0           504610.0              0.0   \n",
       "LOWRY CHARLES P             0.0                0.0              0.0   \n",
       "COLWELL WESLEY        1200000.0            27610.0        -144062.0   \n",
       "MULLER MARK S         1100000.0           842924.0        -719000.0   \n",
       "JACKSON CHARLENE R     250000.0                0.0              0.0   \n",
       "WESTFAHL RICHARD K          0.0                0.0         -10800.0   \n",
       "WALTERS GARETH W            0.0            53625.0              0.0   \n",
       "WALLS JR ROBERT H      850000.0                0.0              0.0   \n",
       "KITCHEN LOUISE        3100000.0                0.0              0.0   \n",
       "CHAN RONNIE                 0.0                0.0         -98784.0   \n",
       "BELFER ROBERT               0.0          -102500.0              0.0   \n",
       "SHANKMAN JEFFREY A    2000000.0                0.0              0.0   \n",
       "WODRASKA JOHN               0.0                0.0              0.0   \n",
       "BERGSIEKER RICHARD P   250000.0                0.0        -485813.0   \n",
       "URQUHART JOHN A             0.0                0.0         -36666.0   \n",
       "BIBI PHILIPPE A       1000000.0                0.0              0.0   \n",
       "...                         ...                ...              ...   \n",
       "REYNOLDS LAWRENCE      100000.0            51365.0        -200000.0   \n",
       "DIMICHELE RICHARD G   1000000.0                0.0              0.0   \n",
       "BHATNAGAR SANJAY            0.0                0.0              0.0   \n",
       "CARTER REBECCA C       300000.0                0.0        -159792.0   \n",
       "BUCHANAN HAROLD G      500000.0                0.0              0.0   \n",
       "YEAP SOON                   0.0                0.0              0.0   \n",
       "MURRAY JULIA H         400000.0                0.0              0.0   \n",
       "GARLAND C KEVIN        850000.0                0.0              0.0   \n",
       "DODSON KEITH            70000.0                0.0              0.0   \n",
       "YEAGER F SCOTT              0.0                0.0              0.0   \n",
       "HIRKO JOSEPH                0.0            10259.0              0.0   \n",
       "DIETRICH JANET R       600000.0                0.0              0.0   \n",
       "DERRICK JR. JAMES V    800000.0                0.0       -1284000.0   \n",
       "FREVERT MARK A        2000000.0          6426990.0       -3367011.0   \n",
       "PAI LOU L             1000000.0                0.0              0.0   \n",
       "BAY FRANKLIN R         400000.0           260455.0        -201641.0   \n",
       "HAYSLETT RODERICK J         0.0                0.0              0.0   \n",
       "FUGH JOHN L                 0.0            50591.0              0.0   \n",
       "FALLON JAMES B        2500000.0                0.0              0.0   \n",
       "KOENIG MARK E          700000.0                0.0              0.0   \n",
       "SAVAGE FRANK                0.0                0.0        -121284.0   \n",
       "IZZO LAWRENCE L             0.0                0.0              0.0   \n",
       "TILNEY ELIZABETH A     300000.0                0.0        -575000.0   \n",
       "MARTIN AMANDA K             0.0            85430.0              0.0   \n",
       "BUY RICHARD B          900000.0           649584.0        -694862.0   \n",
       "GRAMM WENDY L               0.0                0.0              0.0   \n",
       "CAUSEY RICHARD A      1000000.0                0.0        -235000.0   \n",
       "TAYLOR MITCHELL S      600000.0           227449.0              0.0   \n",
       "DONAHUE JR JEFFREY M   800000.0                0.0        -300000.0   \n",
       "GLISAN JR BEN F        600000.0                0.0              0.0   \n",
       "\n",
       "                      director_fees  exercised_stock_options  expenses  \\\n",
       "METTS MARK                      0.0                      0.0   94299.0   \n",
       "BAXTER JOHN C                   0.0                6680544.0   11200.0   \n",
       "ELLIOTT STEVEN                  0.0                4890344.0   78552.0   \n",
       "CORDES WILLIAM R                0.0                 651850.0       0.0   \n",
       "HANNON KEVIN P                  0.0                5538001.0   34039.0   \n",
       "MORDAUNT KRISTINA M             0.0                      0.0   35018.0   \n",
       "MEYER ROCKFORD G                0.0                 493489.0       0.0   \n",
       "MCMAHON JEFFREY                 0.0                1104054.0  137108.0   \n",
       "HORTON STANLEY C                0.0                5210569.0       0.0   \n",
       "PIPER GREGORY F                 0.0                 880290.0   43057.0   \n",
       "HUMPHREY GENE E                 0.0                2282768.0    4994.0   \n",
       "UMANOFF ADAM S                  0.0                      0.0   53122.0   \n",
       "BLACHMAN JEREMY M               0.0                 765313.0   84208.0   \n",
       "SUNDE MARTIN                    0.0                      0.0       0.0   \n",
       "GIBBS DANA R                    0.0                2218275.0       0.0   \n",
       "LOWRY CHARLES P                 0.0                 372205.0       0.0   \n",
       "COLWELL WESLEY                  0.0                      0.0   16514.0   \n",
       "MULLER MARK S                   0.0                1056320.0       0.0   \n",
       "JACKSON CHARLENE R              0.0                 185063.0   10181.0   \n",
       "WESTFAHL RICHARD K              0.0                      0.0   51870.0   \n",
       "WALTERS GARETH W                0.0                1030329.0   33785.0   \n",
       "WALLS JR ROBERT H               0.0                4346544.0   50936.0   \n",
       "KITCHEN LOUISE                  0.0                  81042.0    5774.0   \n",
       "CHAN RONNIE                 98784.0                      0.0       0.0   \n",
       "BELFER ROBERT                3285.0                   3285.0       0.0   \n",
       "SHANKMAN JEFFREY A              0.0                1441898.0  178979.0   \n",
       "WODRASKA JOHN                   0.0                      0.0       0.0   \n",
       "BERGSIEKER RICHARD P            0.0                      0.0   59175.0   \n",
       "URQUHART JOHN A             36666.0                      0.0  228656.0   \n",
       "BIBI PHILIPPE A                 0.0                1465734.0   38559.0   \n",
       "...                             ...                      ...       ...   \n",
       "REYNOLDS LAWRENCE               0.0                4160672.0    8409.0   \n",
       "DIMICHELE RICHARD G             0.0                8191755.0   35812.0   \n",
       "BHATNAGAR SANJAY           137864.0                2604490.0       0.0   \n",
       "CARTER REBECCA C                0.0                      0.0       0.0   \n",
       "BUCHANAN HAROLD G               0.0                 825464.0     600.0   \n",
       "YEAP SOON                       0.0                 192758.0   55097.0   \n",
       "MURRAY JULIA H                  0.0                 400478.0   57580.0   \n",
       "GARLAND C KEVIN                 0.0                 636246.0   48405.0   \n",
       "DODSON KEITH                    0.0                      0.0   28164.0   \n",
       "YEAGER F SCOTT                  0.0                8308552.0   53947.0   \n",
       "HIRKO JOSEPH                    0.0               30766064.0   77978.0   \n",
       "DIETRICH JANET R                0.0                1550019.0    3475.0   \n",
       "DERRICK JR. JAMES V             0.0                8831913.0   51124.0   \n",
       "FREVERT MARK A                  0.0               10433518.0   86987.0   \n",
       "PAI LOU L                       0.0               15364167.0   32047.0   \n",
       "BAY FRANKLIN R                  0.0                      0.0  129142.0   \n",
       "HAYSLETT RODERICK J             0.0                      0.0       0.0   \n",
       "FUGH JOHN L                     0.0                 176378.0       0.0   \n",
       "FALLON JAMES B                  0.0                 940257.0   95924.0   \n",
       "KOENIG MARK E                   0.0                 671737.0  127017.0   \n",
       "SAVAGE FRANK               125034.0                      0.0       0.0   \n",
       "IZZO LAWRENCE L                 0.0                2165172.0   28093.0   \n",
       "TILNEY ELIZABETH A              0.0                 591250.0       0.0   \n",
       "MARTIN AMANDA K                 0.0                2070306.0    8211.0   \n",
       "BUY RICHARD B                   0.0                2542813.0       0.0   \n",
       "GRAMM WENDY L              119292.0                      0.0       0.0   \n",
       "CAUSEY RICHARD A                0.0                      0.0   30674.0   \n",
       "TAYLOR MITCHELL S               0.0                3181250.0       0.0   \n",
       "DONAHUE JR JEFFREY M            0.0                 765920.0   96268.0   \n",
       "GLISAN JR BEN F                 0.0                 384728.0  125978.0   \n",
       "\n",
       "                      from_messages  from_poi_to_this_person  \\\n",
       "METTS MARK                     29.0                     38.0   \n",
       "BAXTER JOHN C                   0.0                      0.0   \n",
       "ELLIOTT STEVEN                  0.0                      0.0   \n",
       "CORDES WILLIAM R               12.0                     10.0   \n",
       "HANNON KEVIN P                 32.0                     32.0   \n",
       "MORDAUNT KRISTINA M             0.0                      0.0   \n",
       "MEYER ROCKFORD G               28.0                      0.0   \n",
       "MCMAHON JEFFREY                48.0                     58.0   \n",
       "HORTON STANLEY C             1073.0                     44.0   \n",
       "PIPER GREGORY F               222.0                     61.0   \n",
       "HUMPHREY GENE E                17.0                     10.0   \n",
       "UMANOFF ADAM S                 18.0                     12.0   \n",
       "BLACHMAN JEREMY M              14.0                     25.0   \n",
       "SUNDE MARTIN                   38.0                     37.0   \n",
       "GIBBS DANA R                   12.0                      0.0   \n",
       "LOWRY CHARLES P                 0.0                      0.0   \n",
       "COLWELL WESLEY                 40.0                    240.0   \n",
       "MULLER MARK S                  16.0                     12.0   \n",
       "JACKSON CHARLENE R             56.0                     25.0   \n",
       "WESTFAHL RICHARD K              0.0                      0.0   \n",
       "WALTERS GARETH W                0.0                      0.0   \n",
       "WALLS JR ROBERT H             146.0                     17.0   \n",
       "KITCHEN LOUISE               1728.0                    251.0   \n",
       "CHAN RONNIE                     0.0                      0.0   \n",
       "BELFER ROBERT                   0.0                      0.0   \n",
       "SHANKMAN JEFFREY A           2681.0                     94.0   \n",
       "WODRASKA JOHN                   0.0                      0.0   \n",
       "BERGSIEKER RICHARD P           59.0                      4.0   \n",
       "URQUHART JOHN A                 0.0                      0.0   \n",
       "BIBI PHILIPPE A                40.0                     23.0   \n",
       "...                             ...                      ...   \n",
       "REYNOLDS LAWRENCE               0.0                      0.0   \n",
       "DIMICHELE RICHARD G             0.0                      0.0   \n",
       "BHATNAGAR SANJAY               29.0                      0.0   \n",
       "CARTER REBECCA C               15.0                     29.0   \n",
       "BUCHANAN HAROLD G             125.0                      0.0   \n",
       "YEAP SOON                       0.0                      0.0   \n",
       "MURRAY JULIA H                 45.0                     11.0   \n",
       "GARLAND C KEVIN                44.0                     10.0   \n",
       "DODSON KEITH                   14.0                     10.0   \n",
       "YEAGER F SCOTT                  0.0                      0.0   \n",
       "HIRKO JOSEPH                    0.0                      0.0   \n",
       "DIETRICH JANET R               63.0                    305.0   \n",
       "DERRICK JR. JAMES V           909.0                     64.0   \n",
       "FREVERT MARK A                 21.0                    242.0   \n",
       "PAI LOU L                       0.0                      0.0   \n",
       "BAY FRANKLIN R                  0.0                      0.0   \n",
       "HAYSLETT RODERICK J          1061.0                     35.0   \n",
       "FUGH JOHN L                     0.0                      0.0   \n",
       "FALLON JAMES B                 75.0                     42.0   \n",
       "KOENIG MARK E                  61.0                     53.0   \n",
       "SAVAGE FRANK                    0.0                      0.0   \n",
       "IZZO LAWRENCE L                19.0                     28.0   \n",
       "TILNEY ELIZABETH A             19.0                     10.0   \n",
       "MARTIN AMANDA K               230.0                      8.0   \n",
       "BUY RICHARD B                1053.0                    156.0   \n",
       "GRAMM WENDY L                   0.0                      0.0   \n",
       "CAUSEY RICHARD A               49.0                     58.0   \n",
       "TAYLOR MITCHELL S              29.0                      0.0   \n",
       "DONAHUE JR JEFFREY M           22.0                    188.0   \n",
       "GLISAN JR BEN F                16.0                     52.0   \n",
       "\n",
       "                      from_this_person_to_poi  loan_advances  \\\n",
       "METTS MARK                                1.0            0.0   \n",
       "BAXTER JOHN C                             0.0            0.0   \n",
       "ELLIOTT STEVEN                            0.0            0.0   \n",
       "CORDES WILLIAM R                          0.0            0.0   \n",
       "HANNON KEVIN P                           21.0            0.0   \n",
       "MORDAUNT KRISTINA M                       0.0            0.0   \n",
       "MEYER ROCKFORD G                          0.0            0.0   \n",
       "MCMAHON JEFFREY                          26.0            0.0   \n",
       "HORTON STANLEY C                         15.0            0.0   \n",
       "PIPER GREGORY F                          48.0            0.0   \n",
       "HUMPHREY GENE E                          17.0            0.0   \n",
       "UMANOFF ADAM S                            0.0            0.0   \n",
       "BLACHMAN JEREMY M                         2.0            0.0   \n",
       "SUNDE MARTIN                             13.0            0.0   \n",
       "GIBBS DANA R                              0.0            0.0   \n",
       "LOWRY CHARLES P                           0.0            0.0   \n",
       "COLWELL WESLEY                           11.0            0.0   \n",
       "MULLER MARK S                             0.0            0.0   \n",
       "JACKSON CHARLENE R                       19.0            0.0   \n",
       "WESTFAHL RICHARD K                        0.0            0.0   \n",
       "WALTERS GARETH W                          0.0            0.0   \n",
       "WALLS JR ROBERT H                         0.0            0.0   \n",
       "KITCHEN LOUISE                          194.0            0.0   \n",
       "CHAN RONNIE                               0.0            0.0   \n",
       "BELFER ROBERT                             0.0            0.0   \n",
       "SHANKMAN JEFFREY A                       83.0            0.0   \n",
       "WODRASKA JOHN                             0.0            0.0   \n",
       "BERGSIEKER RICHARD P                      0.0            0.0   \n",
       "URQUHART JOHN A                           0.0            0.0   \n",
       "BIBI PHILIPPE A                           8.0            0.0   \n",
       "...                                       ...            ...   \n",
       "REYNOLDS LAWRENCE                         0.0            0.0   \n",
       "DIMICHELE RICHARD G                       0.0            0.0   \n",
       "BHATNAGAR SANJAY                          1.0            0.0   \n",
       "CARTER REBECCA C                          7.0            0.0   \n",
       "BUCHANAN HAROLD G                         0.0            0.0   \n",
       "YEAP SOON                                 0.0            0.0   \n",
       "MURRAY JULIA H                            2.0            0.0   \n",
       "GARLAND C KEVIN                          27.0            0.0   \n",
       "DODSON KEITH                              3.0            0.0   \n",
       "YEAGER F SCOTT                            0.0            0.0   \n",
       "HIRKO JOSEPH                              0.0            0.0   \n",
       "DIETRICH JANET R                         14.0            0.0   \n",
       "DERRICK JR. JAMES V                      20.0            0.0   \n",
       "FREVERT MARK A                            6.0      2000000.0   \n",
       "PAI LOU L                                 0.0            0.0   \n",
       "BAY FRANKLIN R                            0.0            0.0   \n",
       "HAYSLETT RODERICK J                      38.0            0.0   \n",
       "FUGH JOHN L                               0.0            0.0   \n",
       "FALLON JAMES B                           37.0            0.0   \n",
       "KOENIG MARK E                            15.0            0.0   \n",
       "SAVAGE FRANK                              0.0            0.0   \n",
       "IZZO LAWRENCE L                           5.0            0.0   \n",
       "TILNEY ELIZABETH A                       11.0            0.0   \n",
       "MARTIN AMANDA K                           0.0            0.0   \n",
       "BUY RICHARD B                            71.0            0.0   \n",
       "GRAMM WENDY L                             0.0            0.0   \n",
       "CAUSEY RICHARD A                         12.0            0.0   \n",
       "TAYLOR MITCHELL S                         0.0            0.0   \n",
       "DONAHUE JR JEFFREY M                     11.0            0.0   \n",
       "GLISAN JR BEN F                           6.0            0.0   \n",
       "\n",
       "                      long_term_incentive      other    poi  restricted_stock  \\\n",
       "METTS MARK                            0.0     1740.0  False          585062.0   \n",
       "BAXTER JOHN C                   1586055.0  2660303.0  False         3942714.0   \n",
       "ELLIOTT STEVEN                        0.0    12961.0  False         1788391.0   \n",
       "CORDES WILLIAM R                      0.0        0.0  False          386335.0   \n",
       "HANNON KEVIN P                  1617011.0    11350.0   True          853064.0   \n",
       "MORDAUNT KRISTINA M                   0.0     1411.0  False          208510.0   \n",
       "MEYER ROCKFORD G                      0.0        0.0  False          462384.0   \n",
       "MCMAHON JEFFREY                  694862.0   297353.0  False          558801.0   \n",
       "HORTON STANLEY C                      0.0        0.0  False         2046079.0   \n",
       "PIPER GREGORY F                       0.0      778.0  False          409554.0   \n",
       "HUMPHREY GENE E                       0.0        0.0  False               0.0   \n",
       "UMANOFF ADAM S                        0.0        0.0  False               0.0   \n",
       "BLACHMAN JEREMY M                831809.0      272.0  False          189041.0   \n",
       "SUNDE MARTIN                     476451.0   111122.0  False          698920.0   \n",
       "GIBBS DANA R                     461912.0        0.0  False               0.0   \n",
       "LOWRY CHARLES P                       0.0        0.0  False          153686.0   \n",
       "COLWELL WESLEY                        0.0   101740.0   True          698242.0   \n",
       "MULLER MARK S                   1725545.0      947.0  False          360528.0   \n",
       "JACKSON CHARLENE R                    0.0     2435.0  False          540672.0   \n",
       "WESTFAHL RICHARD K               256191.0   401130.0  False          384930.0   \n",
       "WALTERS GARETH W                      0.0        0.0  False               0.0   \n",
       "WALLS JR ROBERT H                540751.0        2.0  False         1552453.0   \n",
       "KITCHEN LOUISE                        0.0    93925.0  False          466101.0   \n",
       "CHAN RONNIE                           0.0        0.0  False           32460.0   \n",
       "BELFER ROBERT                         0.0        0.0  False               0.0   \n",
       "SHANKMAN JEFFREY A               554422.0     1191.0  False          630137.0   \n",
       "WODRASKA JOHN                         0.0   189583.0  False               0.0   \n",
       "BERGSIEKER RICHARD P             180250.0   427316.0  False          659249.0   \n",
       "URQUHART JOHN A                       0.0        0.0  False               0.0   \n",
       "BIBI PHILIPPE A                  369721.0   425688.0  False          378082.0   \n",
       "...                                   ...        ...    ...               ...   \n",
       "REYNOLDS LAWRENCE                156250.0   202052.0  False          201483.0   \n",
       "DIMICHELE RICHARD G              694862.0   374689.0  False          126027.0   \n",
       "BHATNAGAR SANJAY                      0.0   137864.0  False        -2604490.0   \n",
       "CARTER REBECCA C                  75000.0      540.0  False          307301.0   \n",
       "BUCHANAN HAROLD G                304805.0     1215.0  False          189041.0   \n",
       "YEAP SOON                             0.0        0.0  False               0.0   \n",
       "MURRAY JULIA H                   125000.0      330.0  False          196983.0   \n",
       "GARLAND C KEVIN                  375304.0    60814.0  False          259907.0   \n",
       "DODSON KEITH                          0.0      774.0  False               0.0   \n",
       "YEAGER F SCOTT                        0.0   147950.0   True         3576206.0   \n",
       "HIRKO JOSEPH                          0.0     2856.0   True               0.0   \n",
       "DIETRICH JANET R                 556416.0      473.0  False          315068.0   \n",
       "DERRICK JR. JAMES V              484000.0     7482.0  False         1787380.0   \n",
       "FREVERT MARK A                  1617011.0  7427621.0  False         4188667.0   \n",
       "PAI LOU L                             0.0  1829457.0  False         8453763.0   \n",
       "BAY FRANKLIN R                        0.0       69.0  False          145796.0   \n",
       "HAYSLETT RODERICK J                   0.0        0.0  False          346663.0   \n",
       "FUGH JOHN L                           0.0        0.0  False               0.0   \n",
       "FALLON JAMES B                   374347.0   401481.0  False         1392142.0   \n",
       "KOENIG MARK E                    300000.0   150458.0   True         1248318.0   \n",
       "SAVAGE FRANK                          0.0        0.0  False               0.0   \n",
       "IZZO LAWRENCE L                  312500.0  1553729.0  False         3654808.0   \n",
       "TILNEY ELIZABETH A               275000.0   152055.0  False          576792.0   \n",
       "MARTIN AMANDA K                 5145434.0  2818454.0  False               0.0   \n",
       "BUY RICHARD B                    769862.0   400572.0  False          901657.0   \n",
       "GRAMM WENDY L                         0.0        0.0  False               0.0   \n",
       "CAUSEY RICHARD A                 350000.0   307895.0   True         2502063.0   \n",
       "TAYLOR MITCHELL S                     0.0        0.0  False          563798.0   \n",
       "DONAHUE JR JEFFREY M                  0.0      891.0  False          315068.0   \n",
       "GLISAN JR BEN F                   71023.0   200308.0   True          393818.0   \n",
       "\n",
       "                      restricted_stock_deferred     salary  \\\n",
       "METTS MARK                                  0.0   365788.0   \n",
       "BAXTER JOHN C                               0.0   267102.0   \n",
       "ELLIOTT STEVEN                              0.0   170941.0   \n",
       "CORDES WILLIAM R                            0.0        0.0   \n",
       "HANNON KEVIN P                              0.0   243293.0   \n",
       "MORDAUNT KRISTINA M                         0.0   267093.0   \n",
       "MEYER ROCKFORD G                            0.0        0.0   \n",
       "MCMAHON JEFFREY                             0.0   370448.0   \n",
       "HORTON STANLEY C                            0.0        0.0   \n",
       "PIPER GREGORY F                       -409554.0   197091.0   \n",
       "HUMPHREY GENE E                             0.0   130724.0   \n",
       "UMANOFF ADAM S                              0.0   288589.0   \n",
       "BLACHMAN JEREMY M                           0.0   248546.0   \n",
       "SUNDE MARTIN                                0.0   257486.0   \n",
       "GIBBS DANA R                                0.0        0.0   \n",
       "LOWRY CHARLES P                       -153686.0        0.0   \n",
       "COLWELL WESLEY                              0.0   288542.0   \n",
       "MULLER MARK S                               0.0   251654.0   \n",
       "JACKSON CHARLENE R                          0.0   288558.0   \n",
       "WESTFAHL RICHARD K                          0.0    63744.0   \n",
       "WALTERS GARETH W                            0.0        0.0   \n",
       "WALLS JR ROBERT H                           0.0   357091.0   \n",
       "KITCHEN LOUISE                              0.0   271442.0   \n",
       "CHAN RONNIE                            -32460.0        0.0   \n",
       "BELFER ROBERT                           44093.0        0.0   \n",
       "SHANKMAN JEFFREY A                          0.0   304110.0   \n",
       "WODRASKA JOHN                               0.0        0.0   \n",
       "BERGSIEKER RICHARD P                        0.0   187922.0   \n",
       "URQUHART JOHN A                             0.0        0.0   \n",
       "BIBI PHILIPPE A                             0.0   213625.0   \n",
       "...                                         ...        ...   \n",
       "REYNOLDS LAWRENCE                     -140264.0    76399.0   \n",
       "DIMICHELE RICHARD G                         0.0   262788.0   \n",
       "BHATNAGAR SANJAY                     15456290.0        0.0   \n",
       "CARTER REBECCA C                      -307301.0   261809.0   \n",
       "BUCHANAN HAROLD G                           0.0   248017.0   \n",
       "YEAP SOON                                   0.0        0.0   \n",
       "MURRAY JULIA H                              0.0   229284.0   \n",
       "GARLAND C KEVIN                             0.0   231946.0   \n",
       "DODSON KEITH                                0.0   221003.0   \n",
       "YEAGER F SCOTT                              0.0   158403.0   \n",
       "HIRKO JOSEPH                                0.0        0.0   \n",
       "DIETRICH JANET R                            0.0   250100.0   \n",
       "DERRICK JR. JAMES V                  -1787380.0   492375.0   \n",
       "FREVERT MARK A                              0.0  1060932.0   \n",
       "PAI LOU L                                   0.0   261879.0   \n",
       "BAY FRANKLIN R                         -82782.0   239671.0   \n",
       "HAYSLETT RODERICK J                         0.0        0.0   \n",
       "FUGH JOHN L                                 0.0        0.0   \n",
       "FALLON JAMES B                              0.0   304588.0   \n",
       "KOENIG MARK E                               0.0   309946.0   \n",
       "SAVAGE FRANK                                0.0        0.0   \n",
       "IZZO LAWRENCE L                             0.0    85274.0   \n",
       "TILNEY ELIZABETH A                          0.0   247338.0   \n",
       "MARTIN AMANDA K                             0.0   349487.0   \n",
       "BUY RICHARD B                               0.0   330546.0   \n",
       "GRAMM WENDY L                               0.0        0.0   \n",
       "CAUSEY RICHARD A                            0.0   415189.0   \n",
       "TAYLOR MITCHELL S                           0.0   265214.0   \n",
       "DONAHUE JR JEFFREY M                        0.0   278601.0   \n",
       "GLISAN JR BEN F                             0.0   274975.0   \n",
       "\n",
       "                      shared_receipt_with_poi  to_messages  total_payments  \\\n",
       "METTS MARK                              702.0        807.0       1061827.0   \n",
       "BAXTER JOHN C                             0.0          0.0       5634343.0   \n",
       "ELLIOTT STEVEN                            0.0          0.0        211725.0   \n",
       "CORDES WILLIAM R                         58.0        764.0             0.0   \n",
       "HANNON KEVIN P                         1035.0       1045.0        288682.0   \n",
       "MORDAUNT KRISTINA M                       0.0          0.0        628522.0   \n",
       "MEYER ROCKFORD G                         22.0        232.0       1848227.0   \n",
       "MCMAHON JEFFREY                        2228.0       2355.0       4099771.0   \n",
       "HORTON STANLEY C                       1074.0       2350.0       3131860.0   \n",
       "PIPER GREGORY F                         742.0       1238.0       1737629.0   \n",
       "HUMPHREY GENE E                         119.0        128.0       3100224.0   \n",
       "UMANOFF ADAM S                           41.0        111.0       1130461.0   \n",
       "BLACHMAN JEREMY M                      2326.0       2475.0       2014835.0   \n",
       "SUNDE MARTIN                           2565.0       2647.0       1545059.0   \n",
       "GIBBS DANA R                             23.0        169.0        966522.0   \n",
       "LOWRY CHARLES P                           0.0          0.0             0.0   \n",
       "COLWELL WESLEY                         1132.0       1758.0       1490344.0   \n",
       "MULLER MARK S                           114.0        136.0       3202070.0   \n",
       "JACKSON CHARLENE R                      117.0        258.0        551174.0   \n",
       "WESTFAHL RICHARD K                        0.0          0.0        762135.0   \n",
       "WALTERS GARETH W                          0.0          0.0         87410.0   \n",
       "WALLS JR ROBERT H                       215.0        671.0       1798780.0   \n",
       "KITCHEN LOUISE                         3669.0       8305.0       3471141.0   \n",
       "CHAN RONNIE                               0.0          0.0             0.0   \n",
       "BELFER ROBERT                             0.0          0.0        102500.0   \n",
       "SHANKMAN JEFFREY A                     1730.0       3221.0       3038702.0   \n",
       "WODRASKA JOHN                             0.0          0.0        189583.0   \n",
       "BERGSIEKER RICHARD P                    233.0        383.0        618850.0   \n",
       "URQUHART JOHN A                           0.0          0.0        228656.0   \n",
       "BIBI PHILIPPE A                        1336.0       1607.0       2047593.0   \n",
       "...                                       ...          ...             ...   \n",
       "REYNOLDS LAWRENCE                         0.0          0.0        394475.0   \n",
       "DIMICHELE RICHARD G                       0.0          0.0       2368151.0   \n",
       "BHATNAGAR SANJAY                        463.0        523.0      15456290.0   \n",
       "CARTER REBECCA C                        196.0        312.0        477557.0   \n",
       "BUCHANAN HAROLD G                        23.0       1088.0       1054637.0   \n",
       "YEAP SOON                                 0.0          0.0         55097.0   \n",
       "MURRAY JULIA H                          395.0       2192.0        812194.0   \n",
       "GARLAND C KEVIN                         178.0        209.0       1566469.0   \n",
       "DODSON KEITH                            114.0        176.0        319941.0   \n",
       "YEAGER F SCOTT                            0.0          0.0        360300.0   \n",
       "HIRKO JOSEPH                              0.0          0.0         91093.0   \n",
       "DIETRICH JANET R                       1902.0       2572.0       1410464.0   \n",
       "DERRICK JR. JAMES V                    1401.0       2181.0        550981.0   \n",
       "FREVERT MARK A                         2979.0       3275.0      17252530.0   \n",
       "PAI LOU L                                 0.0          0.0       3123383.0   \n",
       "BAY FRANKLIN R                            0.0          0.0        827696.0   \n",
       "HAYSLETT RODERICK J                     571.0       2649.0             0.0   \n",
       "FUGH JOHN L                               0.0          0.0         50591.0   \n",
       "FALLON JAMES B                         1604.0       1755.0       3676340.0   \n",
       "KOENIG MARK E                          2271.0       2374.0       1587421.0   \n",
       "SAVAGE FRANK                              0.0          0.0          3750.0   \n",
       "IZZO LAWRENCE L                         437.0        496.0       1979596.0   \n",
       "TILNEY ELIZABETH A                      379.0        460.0        399393.0   \n",
       "MARTIN AMANDA K                         477.0       1522.0       8407016.0   \n",
       "BUY RICHARD B                          2333.0       3523.0       2355702.0   \n",
       "GRAMM WENDY L                             0.0          0.0        119292.0   \n",
       "CAUSEY RICHARD A                       1585.0       1892.0       1868758.0   \n",
       "TAYLOR MITCHELL S                       300.0        533.0       1092663.0   \n",
       "DONAHUE JR JEFFREY M                    772.0        865.0        875760.0   \n",
       "GLISAN JR BEN F                         874.0        873.0       1272284.0   \n",
       "\n",
       "                      total_stock_value  \n",
       "METTS MARK                     585062.0  \n",
       "BAXTER JOHN C                10623258.0  \n",
       "ELLIOTT STEVEN                6678735.0  \n",
       "CORDES WILLIAM R              1038185.0  \n",
       "HANNON KEVIN P                6391065.0  \n",
       "MORDAUNT KRISTINA M            208510.0  \n",
       "MEYER ROCKFORD G               955873.0  \n",
       "MCMAHON JEFFREY               1662855.0  \n",
       "HORTON STANLEY C              7256648.0  \n",
       "PIPER GREGORY F                880290.0  \n",
       "HUMPHREY GENE E               2282768.0  \n",
       "UMANOFF ADAM S                      0.0  \n",
       "BLACHMAN JEREMY M              954354.0  \n",
       "SUNDE MARTIN                   698920.0  \n",
       "GIBBS DANA R                  2218275.0  \n",
       "LOWRY CHARLES P                372205.0  \n",
       "COLWELL WESLEY                 698242.0  \n",
       "MULLER MARK S                 1416848.0  \n",
       "JACKSON CHARLENE R             725735.0  \n",
       "WESTFAHL RICHARD K             384930.0  \n",
       "WALTERS GARETH W              1030329.0  \n",
       "WALLS JR ROBERT H             5898997.0  \n",
       "KITCHEN LOUISE                 547143.0  \n",
       "CHAN RONNIE                         0.0  \n",
       "BELFER ROBERT                  -44093.0  \n",
       "SHANKMAN JEFFREY A            2072035.0  \n",
       "WODRASKA JOHN                       0.0  \n",
       "BERGSIEKER RICHARD P           659249.0  \n",
       "URQUHART JOHN A                     0.0  \n",
       "BIBI PHILIPPE A               1843816.0  \n",
       "...                                 ...  \n",
       "REYNOLDS LAWRENCE             4221891.0  \n",
       "DIMICHELE RICHARD G           8317782.0  \n",
       "BHATNAGAR SANJAY                    0.0  \n",
       "CARTER REBECCA C                    0.0  \n",
       "BUCHANAN HAROLD G             1014505.0  \n",
       "YEAP SOON                      192758.0  \n",
       "MURRAY JULIA H                 597461.0  \n",
       "GARLAND C KEVIN                896153.0  \n",
       "DODSON KEITH                        0.0  \n",
       "YEAGER F SCOTT               11884758.0  \n",
       "HIRKO JOSEPH                 30766064.0  \n",
       "DIETRICH JANET R              1865087.0  \n",
       "DERRICK JR. JAMES V           8831913.0  \n",
       "FREVERT MARK A               14622185.0  \n",
       "PAI LOU L                    23817930.0  \n",
       "BAY FRANKLIN R                  63014.0  \n",
       "HAYSLETT RODERICK J            346663.0  \n",
       "FUGH JOHN L                    176378.0  \n",
       "FALLON JAMES B                2332399.0  \n",
       "KOENIG MARK E                 1920055.0  \n",
       "SAVAGE FRANK                        0.0  \n",
       "IZZO LAWRENCE L               5819980.0  \n",
       "TILNEY ELIZABETH A            1168042.0  \n",
       "MARTIN AMANDA K               2070306.0  \n",
       "BUY RICHARD B                 3444470.0  \n",
       "GRAMM WENDY L                       0.0  \n",
       "CAUSEY RICHARD A              2502063.0  \n",
       "TAYLOR MITCHELL S             3745048.0  \n",
       "DONAHUE JR JEFFREY M          1080988.0  \n",
       "GLISAN JR BEN F                778546.0  \n",
       "\n",
       "[146 rows x 20 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from above table we can see that some of the data can be interrupting with our analysis\n",
    "# so let's get rid off, for example the e-mail address column \n",
    "\n",
    "enron_dataf.drop('email_address', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's load the data and answer a few simple questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we see the whole data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bonus                            5.6e+06\n",
       "deferral_payments                      0\n",
       "deferred_income                        0\n",
       "director_fees                          0\n",
       "email_address                          0\n",
       "exercised_stock_options        1.925e+07\n",
       "expenses                           29336\n",
       "from_messages                        108\n",
       "from_poi_to_this_person               88\n",
       "from_this_person_to_poi               30\n",
       "loan_advances                          0\n",
       "long_term_incentive             1.92e+06\n",
       "other                              22122\n",
       "poi                                 True\n",
       "restricted_stock             6.84367e+06\n",
       "restricted_stock_deferred              0\n",
       "salary                       1.11126e+06\n",
       "shared_receipt_with_poi             2042\n",
       "to_messages                         3627\n",
       "total_payments               8.68272e+06\n",
       "total_stock_value            2.60937e+07\n",
       "Name: SKILLING JEFFREY K, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what features we have about the Enron's CEO:\n",
    "\n",
    "enron_dataf.loc['SKILLING JEFFREY K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'bonus', u'deferral_payments', u'deferred_income', u'director_fees',\n",
      "       u'email_address', u'exercised_stock_options', u'expenses',\n",
      "       u'from_messages', u'from_poi_to_this_person',\n",
      "       u'from_this_person_to_poi', u'loan_advances', u'long_term_incentive',\n",
      "       u'other', u'poi', u'restricted_stock', u'restricted_stock_deferred',\n",
      "       u'salary', u'shared_receipt_with_poi', u'to_messages',\n",
      "       u'total_payments', u'total_stock_value'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print enron_dataf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    128\n",
       "True      18\n",
       "Name: poi, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we see there are 146 people in our dataset. Only 18 of them are POI  - Persons of Interest\n",
    "enron_dataf['poi'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## OUTLIERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nleQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe1e3780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's visualize the salaries and bonuses of ppl in enrone,that's a good way to find outliers\n",
    "\n",
    "plt.scatter(enron_dataf[\"salary\"][enron_dataf[\"poi\"] == True],enron_dataf[\"bonus\"][enron_dataf[\"poi\"] == True], color = 'r',\n",
    "           label = \"POI\")\n",
    "plt.scatter(enron_dataf[\"salary\"][enron_dataf[\"poi\"] == False],enron_dataf[\"bonus\"][enron_dataf[\"poi\"] == False],color = 'b',\n",
    "           label = \"Not-POI\")\n",
    "    \n",
    "plt.xlabel(\"Salary\")\n",
    "plt.ylabel(\"Bonus\")\n",
    "plt.title(\"Scatterplot of salary & bonus\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As we can see there are some outliers that must be removed for further analysis.\n",
    "# let's get rid off the total, which could cause a chaos. \n",
    "# After that we should remove all NANs and see the 6 top salaries as a list in Enron.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removing the NaN values:\n",
    "#enron_dataf.replace(to_replace= 'NaN', value= 0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRETSFBRERCRNQUFERNL+P8wtrcbX2/1eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe180c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let't eliminate the 'Total' counts!\n",
    "# The plot brought a more comprehensive view\n",
    "\n",
    "enron_dataf.drop('TOTAL', axis = 0, inplace = True)\n",
    "\n",
    "plt.scatter(enron_dataf[\"salary\"][enron_dataf[\"poi\"] == True],enron_dataf[\"bonus\"][enron_dataf[\"poi\"] == True], color = 'r',\n",
    "           label = \"POI\")\n",
    "plt.scatter(enron_dataf[\"salary\"][enron_dataf[\"poi\"] == False],enron_dataf[\"bonus\"][enron_dataf[\"poi\"] == False],color = 'b',\n",
    "           label = \"Not-POI\")\n",
    "    \n",
    "plt.xlabel(\"Salary\")\n",
    "plt.ylabel(\"Bonus\")\n",
    "plt.title(\"Scatterplot of salary & bonus after removing outliers\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### FEATURES\n",
    "#2. Feature processing of the dataset about ENRON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Created two new features:\n",
    "enron_dataf['new_feature_from_meassages_to_poi_ratio'] = enron_dataf['from_messages']/enron_dataf['from_poi_to_this_person']\n",
    "enron_dataf['new_feature_to_messages_from_this_person_to_poi_ratio'] = enron_dataf['to_messages']/enron_dataf['from_this_person_to_poi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = ['poi', 'salary', 'bonus', 'expenses', 'deferred_income','total_payments',\n",
    "                 'from_poi_to_this_person', 'from_this_person_to_poi', 'to_messages', \n",
    "                 'from_messages', 'shared_receipt_with_poi', 'exercised_stock_options',\n",
    "                'total_stock_value', 'new_feature_from_meassages_to_poi_ratio', \n",
    "                'new_feature_to_messages_from_this_person_to_poi_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add our new features to the features list, to chyba juz nie ma sensu?\n",
    "#features_list.append('new_feature_from_meassages_to_poi_ratio')\n",
    "#features_list.append('new_feature_to_messages_from_this_person_to_poi_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removing the NaN values:\n",
    "#enron_dataf.replace(to_replace= \"NaN\", value= 0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#enron_dataf.drop('TOTAL', axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enron_dataf = enron_dataf.replace('NaN', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enron_dataf = enron_dataf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enron_dataf.replace(to_replace = 'inf', value= 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enron_dataf = enron_dataf.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bonus                                                    float64\n",
       "deferral_payments                                        float64\n",
       "deferred_income                                          float64\n",
       "director_fees                                            float64\n",
       "email_address                                            float64\n",
       "exercised_stock_options                                  float64\n",
       "expenses                                                 float64\n",
       "from_messages                                            float64\n",
       "from_poi_to_this_person                                  float64\n",
       "from_this_person_to_poi                                  float64\n",
       "loan_advances                                            float64\n",
       "long_term_incentive                                      float64\n",
       "other                                                    float64\n",
       "poi                                                      float64\n",
       "restricted_stock                                         float64\n",
       "restricted_stock_deferred                                float64\n",
       "salary                                                   float64\n",
       "shared_receipt_with_poi                                  float64\n",
       "to_messages                                              float64\n",
       "total_payments                                           float64\n",
       "total_stock_value                                        float64\n",
       "new_feature_from_meassages_to_poi_ratio                  float64\n",
       "new_feature_to_messages_from_this_person_to_poi_ratio    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_dataf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Deleting the row with index 'THE TRAVEL AGENCY IN THE PARK'\n",
    "enron_dataf.drop('THE TRAVEL AGENCY IN THE PARK', axis = 0, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#enron_dataf.drop('email_address', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>new_feature_from_meassages_to_poi_ratio</th>\n",
       "      <th>new_feature_to_messages_from_this_person_to_poi_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94299.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>585062.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365788.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>1061827.0</td>\n",
       "      <td>585062.0</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>267102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>10623258.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <td>350000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-400729.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4890344.0</td>\n",
       "      <td>78552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1788391.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170941.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211725.0</td>\n",
       "      <td>6678735.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>651850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>386335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1038185.0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <td>1500000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3117011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5538001.0</td>\n",
       "      <td>34039.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>853064.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243293.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>288682.0</td>\n",
       "      <td>6391065.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.761905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      bonus  deferral_payments  deferred_income  \\\n",
       "METTS MARK         600000.0                0.0              0.0   \n",
       "BAXTER JOHN C     1200000.0          1295738.0       -1386055.0   \n",
       "ELLIOTT STEVEN     350000.0                0.0        -400729.0   \n",
       "CORDES WILLIAM R        0.0                0.0              0.0   \n",
       "HANNON KEVIN P    1500000.0                0.0       -3117011.0   \n",
       "\n",
       "                  director_fees  email_address  exercised_stock_options  \\\n",
       "METTS MARK                  0.0            0.0                      0.0   \n",
       "BAXTER JOHN C               0.0            0.0                6680544.0   \n",
       "ELLIOTT STEVEN              0.0            0.0                4890344.0   \n",
       "CORDES WILLIAM R            0.0            0.0                 651850.0   \n",
       "HANNON KEVIN P              0.0            0.0                5538001.0   \n",
       "\n",
       "                  expenses  from_messages  from_poi_to_this_person  \\\n",
       "METTS MARK         94299.0           29.0                     38.0   \n",
       "BAXTER JOHN C      11200.0            0.0                      0.0   \n",
       "ELLIOTT STEVEN     78552.0            0.0                      0.0   \n",
       "CORDES WILLIAM R       0.0           12.0                     10.0   \n",
       "HANNON KEVIN P     34039.0           32.0                     32.0   \n",
       "\n",
       "                  from_this_person_to_poi  \\\n",
       "METTS MARK                            1.0   \n",
       "BAXTER JOHN C                         0.0   \n",
       "ELLIOTT STEVEN                        0.0   \n",
       "CORDES WILLIAM R                      0.0   \n",
       "HANNON KEVIN P                       21.0   \n",
       "\n",
       "                                          ...                            poi  \\\n",
       "METTS MARK                                ...                            0.0   \n",
       "BAXTER JOHN C                             ...                            0.0   \n",
       "ELLIOTT STEVEN                            ...                            0.0   \n",
       "CORDES WILLIAM R                          ...                            0.0   \n",
       "HANNON KEVIN P                            ...                            1.0   \n",
       "\n",
       "                  restricted_stock  restricted_stock_deferred    salary  \\\n",
       "METTS MARK                585062.0                        0.0  365788.0   \n",
       "BAXTER JOHN C            3942714.0                        0.0  267102.0   \n",
       "ELLIOTT STEVEN           1788391.0                        0.0  170941.0   \n",
       "CORDES WILLIAM R          386335.0                        0.0       0.0   \n",
       "HANNON KEVIN P            853064.0                        0.0  243293.0   \n",
       "\n",
       "                  shared_receipt_with_poi  to_messages  total_payments  \\\n",
       "METTS MARK                          702.0        807.0       1061827.0   \n",
       "BAXTER JOHN C                         0.0          0.0       5634343.0   \n",
       "ELLIOTT STEVEN                        0.0          0.0        211725.0   \n",
       "CORDES WILLIAM R                     58.0        764.0             0.0   \n",
       "HANNON KEVIN P                     1035.0       1045.0        288682.0   \n",
       "\n",
       "                  total_stock_value  new_feature_from_meassages_to_poi_ratio  \\\n",
       "METTS MARK                 585062.0                                 0.763158   \n",
       "BAXTER JOHN C            10623258.0                                 0.000000   \n",
       "ELLIOTT STEVEN            6678735.0                                 0.000000   \n",
       "CORDES WILLIAM R          1038185.0                                 1.200000   \n",
       "HANNON KEVIN P            6391065.0                                 1.000000   \n",
       "\n",
       "                  new_feature_to_messages_from_this_person_to_poi_ratio  \n",
       "METTS MARK                                               807.000000      \n",
       "BAXTER JOHN C                                              0.000000      \n",
       "ELLIOTT STEVEN                                             0.000000      \n",
       "CORDES WILLIAM R                                                inf      \n",
       "HANNON KEVIN P                                            49.761905      \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_dataf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Converting the above modified dataframe to a dictionary\n",
    "enron_dict = enron_dataf.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To make it easier with further exploration let's set my dataset to a dataset\n",
    "my_dataset = enron_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# enron_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's focus on choosing the features to indentify a POI\n",
    "# I will use only the provided features, POI, financial and email as per below:\n",
    "# POI\n",
    "# Features with email: 'from_messages', 'shared_receipt_with_poi',['fraction_mail_from_poi', 'fraction_mail_to_poi', 'from_poi_to_this_person', 'from_this_person_to_poi', 'to_messages', 'from_messages']\n",
    "# Financial features: ['poi', 'salary', 'bonus','deferral_payments', 'expenses', \n",
    "#                 'restricted_stock_deferred', 'restricted_stock', 'deferred_income','total_payments',\n",
    "#                 'exercised_stock_options', 'total_stock_value', 'restricted_stock']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_dict = pickle.load(open(\"my_dataset.pkl\", \"r\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels, test_size=0.3, \n",
    "                                                                                             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### use KFold for split and validate algorithm\n",
    "from sklearn.cross_validation import KFold\n",
    "kf=KFold(len(labels),3)\n",
    "for train_indices, test_indices in kf:\n",
    "    #make training and testing sets\n",
    "    features_train= [features[ii] for ii in train_indices]\n",
    "    features_test= [features[ii] for ii in test_indices]\n",
    "    labels_train=[labels[ii] for ii in train_indices]\n",
    "    labels_test=[labels[ii] for ii in test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-d1589ac78226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'accuracy before tuning '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train,labels_train)\n",
    "score = clf.score(features_test,labels_test)\n",
    "print 'accuracy before tuning ', score\n",
    "\n",
    "print \"Decision tree algorithm time:\", round(time()-t0, 3), \"s\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Estimator not fitted, call `fit` before `feature_importances_`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-6e83fe9502b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimportances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m#print 'Feature Ranking: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m#for i in range(16):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfeature_importances_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \"\"\"\n\u001b[1;32m    497\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             raise NotFittedError(\"Estimator not fitted, call `fit` before\"\n\u001b[0m\u001b[1;32m    499\u001b[0m                                  \" `feature_importances_`.\")\n\u001b[1;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Estimator not fitted, call `fit` before `feature_importances_`."
     ]
    }
   ],
   "source": [
    "importances = clf.feature_importances_\n",
    "import numpy as np\n",
    "indices = np.argsort(importances)[::-1]\n",
    "#print 'Feature Ranking: '\n",
    "#for i in range(16):\n",
    "#    print \"{} feature {} ({})\".format(i+1,features_list[i+1],importances[indices[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-6a6ad88f7118>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\naive_bayes.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \"\"\"\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m    184\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "### try Naive Bayes for prediction\n",
    "#t0 = time()\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "accuracy = accuracy_score(pred,labels_test)\n",
    "print accuracy\n",
    "\n",
    "print \"NB algorithm time:\", round(time()-t0, 3), \"s\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-91d2920e844a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done in %0.3fs\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "### use manual tuning parameter min_samples_split\n",
    "t0 = time()\n",
    "clf = DecisionTreeClassifier(min_samples_split=5)\n",
    "clf = clf.fit(features_train,labels_train)\n",
    "pred= clf.predict(features_test)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "acc=accuracy_score(labels_test, pred)\n",
    "\n",
    "print \"Validating algorithm:\"\n",
    "print \"accuracy after tuning = \", acc\n",
    "\n",
    "# function for calculation ratio of true positives\n",
    "# out of all positives (true + false)\n",
    "print 'precision = ', precision_score(labels_test,pred)\n",
    "\n",
    "# function for calculation ratio of true positives\n",
    "# out of true positives and false negatives\n",
    "print 'recall = ', recall_score(labels_test,pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-5eab83e53695>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "numpy.isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2, 10, 11, 17, 17, 27, 28, 45, 45, 46, 46, 52, 52, 61, 82, 85, 87,\n",
       "        94, 94, 95, 95], dtype=int64),\n",
       " array([13, 13, 12, 12, 13, 13, 12, 12, 13, 12, 13, 12, 13, 13, 13, 13, 13,\n",
       "        12, 13, 12, 13], dtype=int64))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isnan(features_train) | np.isinf(features_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### dump your classifier, dataset and features_list so\n",
    "### anyone can run/check your results\n",
    "pickle.dump(clf, open(\"my_classifier.pkl\", \"w\") )\n",
    "pickle.dump(data_dict, open(\"my_dataset.pkl\", \"w\") )\n",
    "pickle.dump(features_list, open(\"my_feature_list.pkl\", \"w\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 144 entries, METTS MARK to GLISAN JR BEN F\n",
      "Data columns (total 23 columns):\n",
      "bonus                                                    144 non-null float64\n",
      "deferral_payments                                        144 non-null float64\n",
      "deferred_income                                          144 non-null float64\n",
      "director_fees                                            144 non-null float64\n",
      "email_address                                            144 non-null float64\n",
      "exercised_stock_options                                  144 non-null float64\n",
      "expenses                                                 144 non-null float64\n",
      "from_messages                                            144 non-null float64\n",
      "from_poi_to_this_person                                  144 non-null float64\n",
      "from_this_person_to_poi                                  144 non-null float64\n",
      "loan_advances                                            144 non-null float64\n",
      "long_term_incentive                                      144 non-null float64\n",
      "other                                                    144 non-null float64\n",
      "poi                                                      144 non-null float64\n",
      "restricted_stock                                         144 non-null float64\n",
      "restricted_stock_deferred                                144 non-null float64\n",
      "salary                                                   144 non-null float64\n",
      "shared_receipt_with_poi                                  144 non-null float64\n",
      "to_messages                                              144 non-null float64\n",
      "total_payments                                           144 non-null float64\n",
      "total_stock_value                                        144 non-null float64\n",
      "new_feature_from_meassages_to_poi_ratio                  144 non-null float64\n",
      "new_feature_to_messages_from_this_person_to_poi_ratio    144 non-null float64\n",
      "dtypes: float64(23)\n",
      "memory usage: 32.0+ KB\n"
     ]
    }
   ],
   "source": [
    "enron_dataf.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-0f96b76aa7dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\naive_bayes.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \"\"\"\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m    184\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "prediction = clf.predict(features_test)\n",
    "accuracy = accuracy_score(labels_test, prediction)\n",
    "\n",
    "\n",
    "print \"Accuracy for GaussianNB:\", accuracy\n",
    "print \"GaussianNB time of running algorithm:\", round(time()-t0, 3), \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>new_feature_from_meassages_to_poi_ratio</th>\n",
       "      <th>new_feature_to_messages_from_this_person_to_poi_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [bonus, deferral_payments, deferred_income, director_fees, email_address, exercised_stock_options, expenses, from_messages, from_poi_to_this_person, from_this_person_to_poi, loan_advances, long_term_incentive, other, poi, restricted_stock, restricted_stock_deferred, salary, shared_receipt_with_poi, to_messages, total_payments, total_stock_value, new_feature_from_meassages_to_poi_ratio, new_feature_to_messages_from_this_person_to_poi_ratio]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_dataf[enron_dataf.isin([np.inf, -np.inf, np.nan]).all(axis='columns')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-c16ad0371031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "# Another classifer is a Decision Tree,\n",
    "# it gives certainly bigger accuracy\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# jak cos to to teraz dodalam wieczorem\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train,labels_train)\n",
    "score = clf.score(features_test,labels_test)\n",
    "pred= clf.predict(features_test)\n",
    "print 'accuracy', score\n",
    "\n",
    "print \"Decision tree algorithm time:\", round(time()-t0, 3), \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-ecdb73784a57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"testing time: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"s\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf.fit(features_train, labels_train)\n",
    "prediction = clf.predict(features_test)\n",
    "print \"testing time: \", round(time()-t0, 3), \"s\"\n",
    "print \"Accuracy of DT classifer is  : \",accuracy_score(labels_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-ccf312dd7500>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"testing time: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"s\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Marcela\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "clf.fit(features_train, labels_train)\n",
    "prediction = clf.predict(features_test)\n",
    "print \"testing time: \", round(time()-t0, 3), \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Accuracy can be interpreted as : 85.2% predictions on the total test set have been made correctly.\n",
    "\n",
    "#Precision can be interpreted as : if a person is being classified as a POI by my classifier then there is a 47.6% chance that the person is actually a POI. (i.e., a 47.6% chance of obtaining a true positive condition.)\n",
    "\n",
    "#Recall can be interpreted as : of all the actual POIs considered, 37.7% of all the POIs can be classified correctly as a POI by my classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create final classifer/ \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_features=2, min_samples_split=2,\n",
    "                             criterion='entropy', max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With 146 Enron employers, 18 of which are POIs, the dataset used is both small and is imbalanced. zmien to jakos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration                   Training set observations                   Testing set observations\n",
      "    1     [ 5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]        [0 1 2 3 4]       \n",
      "    2     [ 0  1  2  3  4 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]        [5 6 7 8 9]       \n",
      "    3     [ 0  1  2  3  4  5  6  7  8  9 15 16 17 18 19 20 21 22 23 24]     [10 11 12 13 14]     \n",
      "    4     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 20 21 22 23 24]     [15 16 17 18 19]     \n",
      "    5     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]     [20 21 22 23 24]     \n"
     ]
    }
   ],
   "source": [
    "# moze to potem do validacji?? chyba raczej trzeba uzyc tego pipeline czy cos\n",
    "# simulate splitting a dataset of 25 observations into 5 folds\n",
    "from sklearn.cross_validation import KFold\n",
    "kf = KFold(25, n_folds=5, shuffle=False)\n",
    "\n",
    "# print the contents of each training and testing set\n",
    "print('{} {:^61} {}'.format('Iteration', 'Training set observations', 'Testing set observations'))\n",
    "for iteration, data in enumerate(kf, start=1):\n",
    "    print('{:^9} {} {:^25}'.format(iteration, data[0], data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
